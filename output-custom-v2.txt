2022-04-26 05:20:22 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2022-04-26 05:20:23 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, continue_once=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=4096, max_tokens_valid=4096, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=5, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-04-26 05:20:23 | INFO | fairseq.tasks.translation | [de] dictionary: 33552 types
2022-04-26 05:20:23 | INFO | fairseq.tasks.translation | [en] dictionary: 42022 types
cfg
{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, continue_once=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=5, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}2022-04-26 05:20:24 | INFO | fairseq_cli.train | loading decoder from language models...
2022-04-26 05:20:24 | INFO | fairseq.file_utils | loading archive file /root/cs4650-final-project/wmt19.en
2022-04-26 05:20:27 | INFO | fairseq.tasks.language_modeling | dictionary: 42022 types
2022-04-26 05:20:30 | INFO | fairseq.models.fairseq_model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1000, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/checkpoint/nng/tensorboard_logs/2019-04-04/lm_newscrawl_en.mxup1000000.mlr1.0.tmult2.per959000.csn.lrs0.6.wrm16000.int1e-07.nag.lr5e-05.clp0.1.lyr20.hd16.drp0.1.ffn6144.at_d0.1.rl_d0.1.i1024.m1536.o1024.mxtk2048.tps512.seed1.bm=eos.ngpu128', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 128, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://learnfair1082:12597', 'distributed_port': 12597, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 1000000, 'stop_time_hours': 0.0, 'clip_norm': 0.1, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': 1e-09, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/checkpoint/nng/lm/wmt/20190404/lm_newscrawl_en.mxup1000000.mlr1.0.tmult2.per959000.csn.lrs0.6.wrm16000.int1e-07.nag.lr5e-05.clp0.1.lyr20.hd16.drp0.1.ffn6144.at_d0.1.rl_d0.1.i1024.m1536.o1024.mxtk2048.tps512.seed1.bm=eos.ngpu128', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 959000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 128}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm_gbw', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'relu_dropout': 0.1, 'decoder_embed_dim': 1536, 'decoder_output_dim': 1024, 'decoder_input_dim': 1024, 'decoder_ffn_embed_dim': 6144, 'decoder_layers': 20, 'decoder_attention_heads': 16, 'decoder_normalize_before': True, 'no_decoder_final_norm': True, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': False, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': 512, 'tpu': True}, 'task': {'_name': 'language_modeling', 'data': '/root/cs4650-final-project/wmt19.en', 'sample_break_mode': 'eos', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': 512, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': True, 'use_plasma_view': True, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'nag', 'momentum': 0.99, 'weight_decay': 0.0, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'cosine', 'warmup_updates': 16000, 'warmup_init_lr': 1e-07, 'lr': [5e-05], 'min_lr': 0.0, 't_mult': 2.0, 'lr_period_updates': 959000.0, 'lr_shrink': 0.6, 'max_update': 1000000}, 'scoring': None, 'bpe': {'_name': 'fastbpe', 'bpe_codes': '/root/cs4650-final-project/wmt19.en/bpecodes'}, 'tokenizer': {'_name': 'moses', 'source_lang': 'en', 'target_lang': 'en', 'moses_no_dash_splits': False, 'moses_no_escape': False}, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
Loading codes from /root/cs4650-final-project/wmt19.en/bpecodes ...
Read 30000 codes from the codes file.

no_encoder_attn True
en_lm.decoder.layers
ModuleList(
  (0): TransformerDecoderLayerBase(
    (dropout_module): FairseqDropout()
    (self_attn): MultiheadAttention(
      (dropout_module): FairseqDropout()
      (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
    )
    (activation_dropout_module): FairseqDropout()
    (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=1536, out_features=6144, bias=True)
    (fc2): Linear(in_features=6144, out_features=1536, bias=True)
    (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  )
  (1): TransformerDecoderLayerBase(
    (dropout_module): FairseqDropout()
    (self_attn): MultiheadAttention(
      (dropout_module): FairseqDropout()
      (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
    )
    (activation_dropout_module): FairseqDropout()
    (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=1536, out_features=6144, bias=True)
    (fc2): Linear(in_features=6144, out_features=1536, bias=True)
    (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  )
  (2): TransformerDecoderLayerBase(
    (dropout_module): FairseqDropout()
    (self_attn): MultiheadAttention(
      (dropout_module): FairseqDropout()
      (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
    )
    (activation_dropout_module): FairseqDropout()
    (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=1536, out_features=6144, bias=True)
    (fc2): Linear(in_features=6144, out_features=1536, bias=True)
    (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  )
  (3): TransformerDecoderLayerBase(
    (dropout_module): FairseqDropout()
    (self_attn): MultiheadAttention(
      (dropout_module): FairseqDropout()
      (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
    )
    (activation_dropout_module): FairseqDropout()
    (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=1536, out_features=6144, bias=True)
    (fc2): Linear(in_features=6144, out_features=1536, bias=True)
    (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  )
  (4): TransformerDecoderLayerBase(
    (dropout_module): FairseqDropout()
    (self_attn): MultiheadAttention(
      (dropout_module): FairseqDropout()
      (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
    )
    (activation_dropout_module): FairseqDropout()
    (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=1536, out_features=6144, bias=True)
    (fc2): Linear(in_features=6144, out_features=1536, bias=True)
    (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  )
  (5): TransformerDecoderLayerBase(
    (dropout_module): FairseqDropout()
    (self_attn): MultiheadAttention(
      (dropout_module): FairseqDropout()
      (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
    )
    (activation_dropout_module): FairseqDropout()
    (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=1536, out_features=6144, bias=True)
    (fc2): Linear(in_features=6144, out_features=1536, bias=True)
    (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  )
  (6): TransformerDecoderLayerBase(
    (dropout_module): FairseqDropout()
    (self_attn): MultiheadAttention(
      (dropout_module): FairseqDropout()
      (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
    )
    (activation_dropout_module): FairseqDropout()
    (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=1536, out_features=6144, bias=True)
    (fc2): Linear(in_features=6144, out_features=1536, bias=True)
    (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  )
  (7): TransformerDecoderLayerBase(
    (dropout_module): FairseqDropout()
    (self_attn): MultiheadAttention(
      (dropout_module): FairseqDropout()
      (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
    )
    (activation_dropout_module): FairseqDropout()
    (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=1536, out_features=6144, bias=True)
    (fc2): Linear(in_features=6144, out_features=1536, bias=True)
    (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  )
  (8): TransformerDecoderLayerBase(
    (dropout_module): FairseqDropout()
    (self_attn): MultiheadAttention(
      (dropout_module): FairseqDropout()
      (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
    )
    (activation_dropout_module): FairseqDropout()
    (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=1536, out_features=6144, bias=True)
    (fc2): Linear(in_features=6144, out_features=1536, bias=True)
    (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  )
  (9): TransformerDecoderLayerBase(
    (dropout_module): FairseqDropout()
    (self_attn): MultiheadAttention(
      (dropout_module): FairseqDropout()
      (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
    )
    (activation_dropout_module): FairseqDropout()
    (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=1536, out_features=6144, bias=True)
    (fc2): Linear(in_features=6144, out_features=1536, bias=True)
    (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  )
  (10): TransformerDecoderLayerBase(
    (dropout_module): FairseqDropout()
    (self_attn): MultiheadAttention(
      (dropout_module): FairseqDropout()
      (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
    )
    (activation_dropout_module): FairseqDropout()
    (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=1536, out_features=6144, bias=True)
    (fc2): Linear(in_features=6144, out_features=1536, bias=True)
    (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  )
  (11): TransformerDecoderLayerBase(
    (dropout_module): FairseqDropout()
    (self_attn): MultiheadAttention(
      (dropout_module): FairseqDropout()
      (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
    )
    (activation_dropout_module): FairseqDropout()
    (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=1536, out_features=6144, bias=True)
    (fc2): Linear(in_features=6144, out_features=1536, bias=True)
    (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  )
  (12): TransformerDecoderLayerBase(
    (dropout_module): FairseqDropout()
    (self_attn): MultiheadAttention(
      (dropout_module): FairseqDropout()
      (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
    )
    (activation_dropout_module): FairseqDropout()
    (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=1536, out_features=6144, bias=True)
    (fc2): Linear(in_features=6144, out_features=1536, bias=True)
    (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  )
  (13): TransformerDecoderLayerBase(
    (dropout_module): FairseqDropout()
    (self_attn): MultiheadAttention(
      (dropout_module): FairseqDropout()
      (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
    )
    (activation_dropout_module): FairseqDropout()
    (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=1536, out_features=6144, bias=True)
    (fc2): Linear(in_features=6144, out_features=1536, bias=True)
    (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  )
  (14): TransformerDecoderLayerBase(
    (dropout_module): FairseqDropout()
    (self_attn): MultiheadAttention(
      (dropout_module): FairseqDropout()
      (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
    )
    (activation_dropout_module): FairseqDropout()
    (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=1536, out_features=6144, bias=True)
    (fc2): Linear(in_features=6144, out_features=1536, bias=True)
    (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  )
  (15): TransformerDecoderLayerBase(
    (dropout_module): FairseqDropout()
    (self_attn): MultiheadAttention(
      (dropout_module): FairseqDropout()
      (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
    )
    (activation_dropout_module): FairseqDropout()
    (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=1536, out_features=6144, bias=True)
    (fc2): Linear(in_features=6144, out_features=1536, bias=True)
    (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  )
  (16): TransformerDecoderLayerBase(
    (dropout_module): FairseqDropout()
    (self_attn): MultiheadAttention(
      (dropout_module): FairseqDropout()
      (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
    )
    (activation_dropout_module): FairseqDropout()
    (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=1536, out_features=6144, bias=True)
    (fc2): Linear(in_features=6144, out_features=1536, bias=True)
    (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  )
  (17): TransformerDecoderLayerBase(
    (dropout_module): FairseqDropout()
    (self_attn): MultiheadAttention(
      (dropout_module): FairseqDropout()
      (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
    )
    (activation_dropout_module): FairseqDropout()
    (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=1536, out_features=6144, bias=True)
    (fc2): Linear(in_features=6144, out_features=1536, bias=True)
    (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  )
  (18): TransformerDecoderLayerBase(
    (dropout_module): FairseqDropout()
    (self_attn): MultiheadAttention(
      (dropout_module): FairseqDropout()
      (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
    )
    (activation_dropout_module): FairseqDropout()
    (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=1536, out_features=6144, bias=True)
    (fc2): Linear(in_features=6144, out_features=1536, bias=True)
    (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  )
  (19): TransformerDecoderLayerBase(
    (dropout_module): FairseqDropout()
    (self_attn): MultiheadAttention(
      (dropout_module): FairseqDropout()
      (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
      (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
    )
    (activation_dropout_module): FairseqDropout()
    (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=1536, out_features=6144, bias=True)
    (fc2): Linear(in_features=6144, out_features=1536, bias=True)
    (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  )
)2022-04-26 05:20:33 | INFO | fairseq_cli.train | Swapped decoder from language model
2022-04-26 05:20:33 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(33552, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(42022, 1024, padding_idx=1)
    (project_in_dim): Linear(in_features=1024, out_features=1536, bias=False)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1536, out_features=6144, bias=True)
        (fc2): Linear(in_features=6144, out_features=1536, bias=True)
        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=1536, bias=True)
          (v_proj): Linear(in_features=512, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1536, out_features=6144, bias=True)
        (fc2): Linear(in_features=6144, out_features=1536, bias=True)
        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=1536, bias=True)
          (v_proj): Linear(in_features=512, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1536, out_features=6144, bias=True)
        (fc2): Linear(in_features=6144, out_features=1536, bias=True)
        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=1536, bias=True)
          (v_proj): Linear(in_features=512, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1536, out_features=6144, bias=True)
        (fc2): Linear(in_features=6144, out_features=1536, bias=True)
        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=1536, bias=True)
          (v_proj): Linear(in_features=512, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1536, out_features=6144, bias=True)
        (fc2): Linear(in_features=6144, out_features=1536, bias=True)
        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=1536, bias=True)
          (v_proj): Linear(in_features=512, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1536, out_features=6144, bias=True)
        (fc2): Linear(in_features=6144, out_features=1536, bias=True)
        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=1536, bias=True)
          (v_proj): Linear(in_features=512, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      )
    )
    (project_out_dim): Linear(in_features=1536, out_features=1024, bias=False)
    (output_projection): Linear(in_features=1024, out_features=42022, bias=False)
  )
)
2022-04-26 05:20:33 | INFO | fairseq_cli.train | task: TranslationTask
2022-04-26 05:20:33 | INFO | fairseq_cli.train | model: TransformerModel
2022-04-26 05:20:33 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-04-26 05:20:33 | INFO | fairseq_cli.train | num. shared model params: 326,795,264 (num. trained: 326,795,264)
2022-04-26 05:20:33 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-04-26 05:20:33 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-04-26 05:20:33 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-04-26 05:20:33 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-04-26 05:20:33 | INFO | fairseq.trainer | detected shared parameter: decoder.project_in_dim.bias <- decoder.project_out_dim.bias
2022-04-26 05:20:33 | INFO | fairseq.trainer | detected shared parameter: decoder.project_in_dim.bias <- decoder.output_projection.bias
2022-04-26 05:20:33 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-04-26 05:20:33 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 15.740 GB ; name = NVIDIA RTX A4000                        
2022-04-26 05:20:33 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-04-26 05:20:33 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-04-26 05:20:33 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = None
2022-04-26 05:20:33 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt
2022-04-26 05:20:33 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt
2022-04-26 05:20:33 | INFO | fairseq.trainer | loading train data for epoch 1
2022-04-26 05:20:33 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-04-26 05:20:33 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-04-26 05:20:33 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-04-26 05:20:33 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-04-26 05:20:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2022-04-26 05:20:33 | INFO | fairseq.trainer | begin training epoch 1
2022-04-26 05:20:33 | INFO | fairseq_cli.train | Start iterating over samples

/root/cs4650-final-project/fairseq/fairseq/utils.py:374: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-04-26 05:21:19 | INFO | train_inner | epoch 001:    100 / 1102 loss=11.937, nll_loss=9.744, ppl=857.25, wps=7828.6, ups=2.23, wpb=3507.8, bsz=121.4, num_updates=100, lr=1.25e-05, gnorm=31.884, train_wall=44, gb_free=6.5, wall=46
2022-04-26 05:22:10 | INFO | train_inner | epoch 001:    200 / 1102 loss=8.577, nll_loss=7.086, ppl=135.88, wps=6960, ups=1.95, wpb=3563.2, bsz=141.4, num_updates=200, lr=2.5e-05, gnorm=7.613, train_wall=50, gb_free=6.3, wall=97
2022-04-26 05:23:03 | INFO | train_inner | epoch 001:    300 / 1102 loss=8.044, nll_loss=6.594, ppl=96.62, wps=6714.4, ups=1.88, wpb=3572.2, bsz=133.4, num_updates=300, lr=3.75e-05, gnorm=11.983, train_wall=52, gb_free=6.4, wall=150
2022-04-26 05:23:58 | INFO | train_inner | epoch 001:    400 / 1102 loss=7.672, nll_loss=6.221, ppl=74.58, wps=6712.7, ups=1.83, wpb=3671.1, bsz=158.7, num_updates=400, lr=5e-05, gnorm=16.95, train_wall=54, gb_free=6.2, wall=205
2022-04-26 05:24:52 | INFO | train_inner | epoch 001:    500 / 1102 loss=7.512, nll_loss=6.066, ppl=67, wps=6695.9, ups=1.84, wpb=3646.3, bsz=152.7, num_updates=500, lr=6.25e-05, gnorm=17.474, train_wall=54, gb_free=6.9, wall=259
2022-04-26 05:25:46 | INFO | train_inner | epoch 001:    600 / 1102 loss=7.32, nll_loss=5.873, ppl=58.6, wps=6639.1, ups=1.85, wpb=3585.1, bsz=156.3, num_updates=600, lr=7.5e-05, gnorm=15.379, train_wall=53, gb_free=6.5, wall=313
2022-04-26 05:26:40 | INFO | train_inner | epoch 001:    700 / 1102 loss=7.144, nll_loss=5.704, ppl=52.12, wps=6631.2, ups=1.85, wpb=3576.4, bsz=163.6, num_updates=700, lr=8.75e-05, gnorm=14.098, train_wall=53, gb_free=6.1, wall=367
2022-04-26 05:27:34 | INFO | train_inner | epoch 001:    800 / 1102 loss=7.115, nll_loss=5.671, ppl=50.97, wps=6692.3, ups=1.86, wpb=3590.6, bsz=137.3, num_updates=800, lr=0.0001, gnorm=14.035, train_wall=53, gb_free=6.4, wall=421
2022-04-26 05:28:27 | INFO | train_inner | epoch 001:    900 / 1102 loss=6.997, nll_loss=5.567, ppl=47.42, wps=6635.6, ups=1.87, wpb=3547.8, bsz=139.6, num_updates=900, lr=0.0001125, gnorm=13.064, train_wall=53, gb_free=6.3, wall=474
2022-04-26 05:29:21 | INFO | train_inner | epoch 001:   1000 / 1102 loss=6.916, nll_loss=5.488, ppl=44.87, wps=6719.7, ups=1.87, wpb=3594, bsz=153.3, num_updates=1000, lr=0.000125, gnorm=12.135, train_wall=53, gb_free=6.6, wall=528
2022-04-26 05:30:14 | INFO | train_inner | epoch 001:   1100 / 1102 loss=6.874, nll_loss=5.454, ppl=43.82, wps=6681.1, ups=1.88, wpb=3561.2, bsz=142, num_updates=1100, lr=0.0001375, gnorm=13.363, train_wall=53, gb_free=6.2, wall=581
2022-04-26 05:30:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-04-26 05:30:17 | INFO | fairseq.tasks.translation | example hypothesis: you don't know what you're going to do.
2022-04-26 05:30:17 | INFO | fairseq.tasks.translation | example reference: they're just not moving.
2022-04-26 05:30:18 | INFO | fairseq.tasks.translation | example hypothesis: and then i said, "what?"
2022-04-26 05:30:18 | INFO | fairseq.tasks.translation | example reference: i was like "what?"
2022-04-26 05:30:20 | INFO | fairseq.tasks.translation | example hypothesis: is it the right?
2022-04-26 05:30:20 | INFO | fairseq.tasks.translation | example reference: is it all worked out? no.
2022-04-26 05:30:21 | INFO | fairseq.tasks.translation | example hypothesis: we need to be able to do that.
2022-04-26 05:30:21 | INFO | fairseq.tasks.translation | example reference: we need to use less to make more.
2022-04-26 05:30:23 | INFO | fairseq.tasks.translation | example hypothesis: but he said, "yes. but no.
2022-04-26 05:30:23 | INFO | fairseq.tasks.translation | example reference: but homage to singUNKNOWNTOKENINREF re.
2022-04-26 05:30:24 | INFO | fairseq.tasks.translation | example hypothesis: we said, "we're going to do this. we're going to do this."
2022-04-26 05:30:24 | INFO | fairseq.tasks.translation | example reference: we call this UNKNOWNTOKENINREF tational lensing.
2022-04-26 05:30:26 | INFO | fairseq.tasks.translation | example hypothesis: now, if you look at this, you can see that there's a lot of people in the united states.
2022-04-26 05:30:26 | INFO | fairseq.tasks.translation | example reference: well, consider by UNKNOWNTOKENINREF y, the concept of physical health.
2022-04-26 05:30:27 | INFO | fairseq.tasks.translation | example hypothesis: these are the people who are the most important people in the world.
2022-04-26 05:30:27 | INFO | fairseq.tasks.translation | example reference: these are the classic conditions that create regret.
2022-04-26 05:30:29 | INFO | fairseq.tasks.translation | example hypothesis: or, or, or, or, or, or, or, or, or, or, or, or, or, or or
2022-04-26 05:30:29 | INFO | fairseq.tasks.translation | example reference: valence means good or bad, positive or negative.
2022-04-26 05:30:30 | INFO | fairseq.tasks.translation | example hypothesis: it's the most important thing to do. it's the most important thing to do.
2022-04-26 05:30:30 | INFO | fairseq.tasks.translation | example reference: the bad news is they're rocket fuels.
2022-04-26 05:30:32 | INFO | fairseq.tasks.translation | example hypothesis: it can be used as a tool.
2022-04-26 05:30:32 | INFO | fairseq.tasks.translation | example reference: it can be used for calculating UNKNOWNTOKENINREF equations of all different types.
2022-04-26 05:30:34 | INFO | fairseq.tasks.translation | example hypothesis: we're going to do this and we're going to do this and we're going to do this and we're going to do this.
2022-04-26 05:30:34 | INFO | fairseq.tasks.translation | example reference: we should probably slow down, and that point of action is probably now.
2022-04-26 05:30:35 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be able to see the UNKNOWNTOKENINHYP and we're going to be able to see the UNKNOWNTOKENINHYP and we're going to be able to see the
2022-04-26 05:30:35 | INFO | fairseq.tasks.translation | example reference: decided to use UNKNOWNTOKENINREF ed content from cement and steel manufacturing.
2022-04-26 05:30:37 | INFO | fairseq.tasks.translation | example hypothesis: we're in the middle of the UNKNOWNTOKENINHYP in the UNKNOWNTOKENINHYP in the UNKNOWNTOKENINHYP in the last two years.
2022-04-26 05:30:37 | INFO | fairseq.tasks.translation | example reference: just in the last two days, we got the new temperature UNKNOWNTOKENINREF ds in UNKNOWNTOKENINREF ary.
2022-04-26 05:30:39 | INFO | fairseq.tasks.translation | example hypothesis: that's a very important thing to do.
2022-04-26 05:30:39 | INFO | fairseq.tasks.translation | example reference: and to remind you that here is an example in which architecture actually did something.
2022-04-26 05:30:40 | INFO | fairseq.tasks.translation | example hypothesis: this was the first time in the history of the united states that these people had been able to do this in the united states.
2022-04-26 05:30:40 | INFO | fairseq.tasks.translation | example reference: and the grandmother had never let any westerners ever see her.
2022-04-26 05:30:42 | INFO | fairseq.tasks.translation | example hypothesis: so we don't know what we're going to do.
2022-04-26 05:30:42 | INFO | fairseq.tasks.translation | example reference: this is something we've actually known for a while, so it's not a real breakthrough.
2022-04-26 05:30:44 | INFO | fairseq.tasks.translation | example hypothesis: it's a little bit more than a little bit more than a little bit more than a little bit more than a little bit more than a little bit more.
2022-04-26 05:30:44 | INFO | fairseq.tasks.translation | example reference: it's a social awkwardness like you're a stranger in a foreign land.
2022-04-26 05:30:45 | INFO | fairseq.tasks.translation | example hypothesis: it was my first time i was in the room, and i was not allowed to go to school.
2022-04-26 05:30:45 | INFO | fairseq.tasks.translation | example reference: i had learned to read music by then, or slowly learning to read music.
2022-04-26 05:30:47 | INFO | fairseq.tasks.translation | example hypothesis: we don't know what we're going to do. we don't know what we're going to do.
2022-04-26 05:30:47 | INFO | fairseq.tasks.translation | example reference: they said they were going to beat us up if we didn't make some gunpowder for them.
2022-04-26 05:30:49 | INFO | fairseq.tasks.translation | example hypothesis: now, we've got a lot of people, we've got a lot of people, we've got lots of people, we've got lots of people.
2022-04-26 05:30:49 | INFO | fairseq.tasks.translation | example reference: well, we collect data from satellites, from airplanes, from ground UNKNOWNTOKENINREF cles, from people.
2022-04-26 05:30:51 | INFO | fairseq.tasks.translation | example hypothesis: and this was the first time in the history of the UNKNOWNTOKENINHYP and the UNKNOWNTOKENINHYP and the UNKNOWNTOKENINHYP and the UNKNOWNTOKENINHYP and the UNKNOWNTOKENINHYP.
2022-04-26 05:30:51 | INFO | fairseq.tasks.translation | example reference: and one of the UNKNOWNTOKENINREF things that happened was this act of actually connecting to all these people.
2022-04-26 05:30:52 | INFO | fairseq.tasks.translation | example hypothesis: i'm going to show you a couple of examples of what i'm going to show you.
2022-04-26 05:30:52 | INFO | fairseq.tasks.translation | example reference: i want to share one story about an innovation called drip irriUNKNOWNTOKENINREF.
2022-04-26 05:30:54 | INFO | fairseq.tasks.translation | example hypothesis: and this was the first time in my life that i had ever been in the room, and this was the first time in my life that i had ever been in the room.
2022-04-26 05:30:54 | INFO | fairseq.tasks.translation | example reference: the man, his name was mahmoud, and the child, whose name was rafi, left.
2022-04-26 05:30:56 | INFO | fairseq.tasks.translation | example hypothesis: and there was no way to do it.
2022-04-26 05:30:56 | INFO | fairseq.tasks.translation | example reference: and that allows me to check my timer discretely, here, without bending my elbow.
2022-04-26 05:30:58 | INFO | fairseq.tasks.translation | example hypothesis: in this case, we're in the middle of the road, in the middle of the road.
2022-04-26 05:30:58 | INFO | fairseq.tasks.translation | example reference: she arrived at our reserve from a reserve east of us on her UNKNOWNTOKENINREF atory route.
2022-04-26 05:30:59 | INFO | fairseq.tasks.translation | example hypothesis: if we can do that, we'll be able to do that if we can do that.
2022-04-26 05:30:59 | INFO | fairseq.tasks.translation | example reference: if we can make it through the next 150 years, i think that your great great grandchildren will forget all about malthus.
2022-04-26 05:31:01 | INFO | fairseq.tasks.translation | example hypothesis: and then you can see how these UNKNOWNTOKENINHYP can be used to make things like this, and how they can be used to make things like this.
2022-04-26 05:31:01 | INFO | fairseq.tasks.translation | example reference: those are then selected by the UNKNOWNTOKENINREF m, reproduced with mutation and reUNKNOWNTOKENINREF ations to introduce sex as well.
2022-04-26 05:31:03 | INFO | fairseq.tasks.translation | example hypothesis: but it doesn't really matter how much it cost, it doesn't really matter how much it cost, it doesn't really matter how much it cost.
2022-04-26 05:31:03 | INFO | fairseq.tasks.translation | example reference: now, it just shouldn't take these sorts of efforts to find out where the money in deals like this went.
2022-04-26 05:31:04 | INFO | fairseq.tasks.translation | example hypothesis: if you don't think that if you don't think that if you don't think that if you don't think that if you don't think that if you don't think that if you don't think that if you don't
2022-04-26 05:31:04 | INFO | fairseq.tasks.translation | example reference: when people don't take their pills, when people don't follow doctors' orders -- these are behavior problems.
2022-04-26 05:31:06 | INFO | fairseq.tasks.translation | example hypothesis: so it's a very simple way to think about the world as a whole, as well as the world as a whole.
2022-04-26 05:31:06 | INFO | fairseq.tasks.translation | example reference: so it's pretty sad to find that UNKNOWNTOKENINREF es, like so many other UNKNOWNTOKENINREF around the world, are losing their habitats.
2022-04-26 05:31:08 | INFO | fairseq.tasks.translation | example hypothesis: we think we're going to have a lot of us in this room and we're going to have a lot of us in this room and we're going to have a lot of us in this room.
2022-04-26 05:31:08 | INFO | fairseq.tasks.translation | example reference: we discovered bluegrass a few years ago, and we fell in love with it. we hope you guys will too.
2022-04-26 05:31:09 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to have a lot of questions, we're going to have a lot of questions, we're going to have a lot of questions, we're going to have a lot of questions.
2022-04-26 05:31:09 | INFO | fairseq.tasks.translation | example reference: so i was trying to, you know, take the engineer's version: can we build a mechanical system in inorganic materials that will do the same thing?
2022-04-26 05:31:11 | INFO | fairseq.tasks.translation | example hypothesis: we've been able to make a lot of the UNKNOWNTOKENINHYP we've been talking about today. we've been able to make a lot of the UNKNOWNTOKENINHYP we've been talking about today.
2022-04-26 05:31:11 | INFO | fairseq.tasks.translation | example reference: we consult to the media about canopy questions; we have a canopy newsletter; we have an email listserv.
2022-04-26 05:31:13 | INFO | fairseq.tasks.translation | example hypothesis: and it turns out that it's actually a very simple way to do it, and it turns out that it's actually a very simple way to do it.
2022-04-26 05:31:13 | INFO | fairseq.tasks.translation | example reference: what my purpose of the talk today really is, is to sort of indelibly scar your minds with these charismatic and majestic UNKNOWNTOKENINREF.
2022-04-26 05:31:15 | INFO | fairseq.tasks.translation | example hypothesis: so it's not so good, it's so bad, it's so bad, it's so bad, it's so bad, it's so bad, it's so bad, it's so bad, it's so bad, it's so bad.
2022-04-26 05:31:15 | INFO | fairseq.tasks.translation | example reference: now, it's no surprise that when you add consecutive fibonacci numbers, you get the next fibonacci number. right?
2022-04-26 05:31:17 | INFO | fairseq.tasks.translation | example hypothesis: but we don't know what we're going to do, and we don't know what we're going to do. we don't know what we're going to do.
2022-04-26 05:31:17 | INFO | fairseq.tasks.translation | example reference: yet we dither, taking no action to deflect the UNKNOWNTOKENINREF id, even though the longer we wait, the more difficult and expensive it becomes. "
2022-04-26 05:31:18 | INFO | fairseq.tasks.translation | example hypothesis: he had a very simple idea of what he wanted to do when he was a kid. he had a very simple idea of what he wanted to do.
2022-04-26 05:31:18 | INFO | fairseq.tasks.translation | example reference: he had this amazing series of hairs growing out of a mole on the left side of his face, which i'm told is very good luck.
2022-04-26 05:31:20 | INFO | fairseq.tasks.translation | example hypothesis: this is one of the most beautiful UNKNOWNTOKENINHYP in the world, and this is one of the most beautiful UNKNOWNTOKENINHYP in the world, and this is one of the most beautiful UNKNOWNTOKENINHYP in the world.
2022-04-26 05:31:20 | INFO | fairseq.tasks.translation | example reference: here's the first battery -- a stack of coins, zinc and silver, separated by cardboard soaked in brine.
2022-04-26 05:31:22 | INFO | fairseq.tasks.translation | example hypothesis: this was the first time in the history of the united states that we've been able to get a lot of people in the united states out of poverty.
2022-04-26 05:31:22 | INFO | fairseq.tasks.translation | example reference: durkheim called this level the level of the sacred because he believed that the function of religion was to unite people into a group, into a moral community.
2022-04-26 05:31:24 | INFO | fairseq.tasks.translation | example hypothesis: but if you look at the UNKNOWNTOKENINHYP, i think it's a little bit more than a little bit more than a little bit more than a little bit more than a little bit more than a little bit more than a little bit more than a little bit more than a little bit more.
2022-04-26 05:31:24 | INFO | fairseq.tasks.translation | example reference: but the UNKNOWNTOKENINREF match up if i rotate by a sixth of a turn around the point where all the trianUNKNOWNTOKENINREF meet.
2022-04-26 05:31:26 | INFO | fairseq.tasks.translation | example hypothesis: and if you think about it, if you think about it, if you think about it, if you think about it, if you think about it, if you think about it, if you think about it, if you think about it, if you think about it, if you think about it
2022-04-26 05:31:26 | INFO | fairseq.tasks.translation | example reference: there's little brochures all around outside, and if any of you have anything to do with children and care about their future, i beg that you pick up that brochure.
2022-04-26 05:31:28 | INFO | fairseq.tasks.translation | example hypothesis: and this is the first time in the history of the united nations, in the united states, in the united states, in the united states, in the united states, in the united states, in the united states.
2022-04-26 05:31:28 | INFO | fairseq.tasks.translation | example reference: and this is only done in four hours, 50 times faster than the current state of the art, at a cost that will be five to 500 times cheaper than the current options.
2022-04-26 05:31:30 | INFO | fairseq.tasks.translation | example hypothesis: and i think that if you look at the UNKNOWNTOKENINHYP, you can see that there's a lot of people in the UNKNOWNTOKENINHYP, and if you look at the UNKNOWNTOKENINHYP, you can see that there's a lot of people in the UNKNOWNTOKENINHYP, and if you look at the UNKNOWNTOKENINHYP.
2022-04-26 05:31:30 | INFO | fairseq.tasks.translation | example reference: i'm fascinated with the idea of what happens when you merge UNKNOWNTOKENINREF with technology, and i remember reading about this idea of being able to reprogram UNKNOWNTOKENINREF, in the future, away from disease and aging.
2022-04-26 05:31:31 | INFO | fairseq.tasks.translation | example hypothesis: but in fact, it's very, very hard to do that, because it's very, very hard to do that, but it's very hard to do that.
2022-04-26 05:31:31 | INFO | fairseq.tasks.translation | example reference: but the problem with relying on rules and inUNKNOWNTOKENINREF ves is that they demorUNKNOWNTOKENINREF professional activity, and they demorUNKNOWNTOKENINREF professional activity in two UNKNOWNTOKENINREF.
2022-04-26 05:31:33 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "i'm going to show you what we're going to do," and i said, "we're going to show you what we're going to do. we're going to show you what we're going to do.
2022-04-26 05:31:33 | INFO | fairseq.tasks.translation | example reference: i belong to an internet discussion forum, an UNKNOWNTOKENINREF internet discussion forum, and i asked them, i said, "since 1960, we've had exactly 204 UNKNOWNTOKENINREF heads of state, since 1960."
2022-04-26 05:31:35 | INFO | fairseq.tasks.translation | example hypothesis: and i thought, "well, i'm going to show you some examples, and i'm going to show you some examples, and i'm going to show you some examples, and i'm going to show you some examples.
2022-04-26 05:31:35 | INFO | fairseq.tasks.translation | example reference: and as these dark clouds were circling me, and i was finding it really, really difficult to think of anything good, i said to myself that i really needed a way to focus on the positive somehow.
2022-04-26 05:31:37 | INFO | fairseq.tasks.translation | example hypothesis: so, you can see that there's a lot of people in this room, like, you know, a lot of people in this room, like, you know, a lot of people in this room, like, you know, a lot of people in this room, like, you know, a lot of people in this room.
2022-04-26 05:31:37 | INFO | fairseq.tasks.translation | example reference: for example, gUNKNOWNTOKENINREF age discharge, something you would think just simply goes away, but the laws regulating ship discharge of gUNKNOWNTOKENINREF age actually get weaker the further you are from shore.
2022-04-26 05:31:39 | INFO | fairseq.tasks.translation | example hypothesis: so he went back to his car, and he said, "there's a lot of people here, there's a lot of people here, there's a lot of people here, there's a lot of people here."
2022-04-26 05:31:39 | INFO | fairseq.tasks.translation | example reference: see, he owned a UNKNOWNTOKENINREF mium plating company, and they had to move heavy steel parts between tanks of chemicals, and so he needed an industrial robot like this that could basically do the heavy lifting.
2022-04-26 05:31:41 | INFO | fairseq.tasks.translation | example hypothesis: and the way that UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP.
2022-04-26 05:31:41 | INFO | fairseq.tasks.translation | example reference: and the religious police imposes the supposed UNKNOWNTOKENINREF ic way of life on every citizen, by force -- like women are forced to cover their heads -- wear the hijab, the UNKNOWNTOKENINREF ic head cover.
2022-04-26 05:31:43 | INFO | fairseq.tasks.translation | example hypothesis: and if you look at the UNKNOWNTOKENINHYP m of the UNKNOWNTOKENINHYP m of the UNKNOWNTOKENINHYP m of the UNKNOWNTOKENINHYP m of the UNKNOWNTOKENINHYP m of the UNKNOWNTOKENINHYP m of the UNKNOWNTOKENINHYP m of the UNKNOWNTOKENINHYP m of the UNKNOWNTOKENINHYP m of the UNKNOWNTOKENINHYP m of the UNKNOWNTOKENINHYP m of the UNKNOWNTOKENINHYP m of the UNKNOWNTOKENINHYP m of the UNKNOWNTOKENINHYP m of the UNKNOWNTOKENINHYP m of the UNKNOWNTOKENINHYP m.
2022-04-26 05:31:43 | INFO | fairseq.tasks.translation | example reference: come with me to the bottom of the world, antUNKNOWNTOKENINREF tica, the highest, driest, windiest, and yes, coldest region on earth -- more arid than the UNKNOWNTOKENINREF a and, in parts, colder than UNKNOWNTOKENINREF.
2022-04-26 05:31:45 | INFO | fairseq.tasks.translation | example hypothesis: here, here, here, here, here, here, here, here, here, here, here, here, here.
2022-04-26 05:31:45 | INFO | fairseq.tasks.translation | example reference: that's kellar autumn, my former ph.d. student, professor now at lewis and clark, literally giving his firUNKNOWNTOKENINREF born child up for this test.
2022-04-26 05:31:47 | INFO | fairseq.tasks.translation | example hypothesis: it turns out that it's not the only thing we need to do, it's the only thing we need to do, and it's the only thing we need to do.
2022-04-26 05:31:47 | INFO | fairseq.tasks.translation | example reference: however, while it's easier to think of us, the citizens, the police, the army, as the good guys, and them, the narcos, the carteles, as the bad guys, if you think about it, the latter are only providing a service to the former.
2022-04-26 05:31:49 | INFO | fairseq.tasks.translation | example hypothesis: and i think that in the last two years, in the last two years, in the last two years, in the last two years, in the last two years, in the last two years, in the last two years, in the last two years, in the last two years, in the last two years, in the last two years, in the last two years.
2022-04-26 05:31:49 | INFO | fairseq.tasks.translation | example reference: and for the following 25 years, living in italy, living in UNKNOWNTOKENINREF, i doled out a piece of this romance to anybody who'd pay for it -- this sense, this aesthetic feeling, for the experience revolving around a designed object.
2022-04-26 05:31:51 | INFO | fairseq.tasks.translation | example hypothesis: we know that we're not going to be able to do this, we're not going to be able to do this, we're not going to be able to do this, we're not going to be able to do this, we're not going to be able to do this, we're not going to be able to do this, we're not going to be able to do this.
2022-04-26 05:31:51 | INFO | fairseq.tasks.translation | example reference: because we've UNKNOWNTOKENINREF the problem in chubut province, which is like a state in argentina where punta tombo is -- so that's about 1,000 UNKNOWNTOKENINREF of coastline -- but we haven't UNKNOWNTOKENINREF the problem in northern argentina, uruguay and UNKNOWNTOKENINREF.
2022-04-26 05:31:53 | INFO | fairseq.tasks.translation | example hypothesis: and we said, "well, you know, we're going to do it, we're going to do it, we're going to do it, we're going to do it, we're going to do it, we're going to do it, we're going to do it."
2022-04-26 05:31:53 | INFO | fairseq.tasks.translation | example reference: animal fan nellie mckay sings a sparkling UNKNOWNTOKENINREF te to her dear dog. she suggests we all do the same: "just go right to the pound / and find yourself a hound / and make that doggie proud / 'cause that's what it's all about."
2022-04-26 05:31:56 | INFO | fairseq.tasks.translation | example hypothesis: and this is the first time in the history of human UNKNOWNTOKENINHYP, the first time in the history of human UNKNOWNTOKENINHYP, the first time in the history of human UNKNOWNTOKENINHYP, the first time in the history of human UNKNOWNTOKENINHYP, the first time in the history of human UNKNOWNTOKENINHYP, the first time in the history of human UNKNOWNTOKENINHYP, the first time in the history of human UNKNOWNTOKENINHYP, the first time in the history of human UNKNOWNTOKENINHYP.
2022-04-26 05:31:56 | INFO | fairseq.tasks.translation | example reference: with streams and rivers drying up because of over-usage, rob harmon has UNKNOWNTOKENINREF mented an ingenious market mechanism to bring back the water. farmers and beer companies find their fates intertwined in the intriguing centurUNKNOWNTOKENINREF old tale of prickly pear creek. & lt; em & gt; & lt; / em & gt;
2022-04-26 05:31:58 | INFO | fairseq.tasks.translation | example hypothesis: we don't know what to do, and we don't know what to do, and we don't know what to do, and we don't know what to do.
2022-04-26 05:31:58 | INFO | fairseq.tasks.translation | example reference: and the reality of the society that we're in is there are thousands and thousands of people out there leading lives of quiet, screaming desperation, where they work long, hard hours at jobs they hate to enable them to buy things they don't need to impress people they don't like.
2022-04-26 05:32:00 | INFO | fairseq.tasks.translation | example hypothesis: and i think it's a very important thing to think about, and i think it's a very important thing to think about, and i think it's a very important thing to think about, and it's a very important thing to think about.
2022-04-26 05:32:00 | INFO | fairseq.tasks.translation | example reference: and i organize it. and, well, it's also a bit different because an UNKNOWNTOKENINREF versus, let's say, a dance company finally is a negotiation between one's private world, one's UNKNOWNTOKENINREF tual world, the world of ideas, the world of aspirations, of UNKNOWNTOKENINREF tions, with the relationship of the exterior world and all the limitations, the naysayers.
2022-04-26 05:32:02 | INFO | fairseq.tasks.translation | example hypothesis: and we need to think about this, and we need to think about it, and we need to think about it, and we need to think about it, and we need to think about it.
2022-04-26 05:32:02 | INFO | fairseq.tasks.translation | example reference: and i also hope that you share the idea that if engineers and UNKNOWNTOKENINREF can use all these different climatic parameters, it will be possible to create really good and comfortable outdoor conditions, to change our thermal perception that we feel comfortable in an outdoor environment, and we can do that with the best passive design, but also using the energy source of the site in qatar which is the sun.
2022-04-26 05:32:05 | INFO | fairseq.tasks.translation | example hypothesis: i mean, i think it's a very simple idea, but i think it's a very simple idea, i think it's a very simple idea, i think it's a very simple idea, i think it's a very simple idea, i think it's a very simple idea, i think it's a very simple idea, i think it's a very simple idea, i think it's a very simple idea, i think it's a very simple idea, i think it's a very simple idea.
2022-04-26 05:32:05 | INFO | fairseq.tasks.translation | example reference: i used to say that these people saved me, but what i now know is they did something even more important in that they empowered me to save myself, and crucially, they helped me to understand something which i'd always UNKNOWNTOKENINREF pected: that my voices were a meaningful response to traumatic life events, particularly childhood events, and as such were not my enemies but a source of insight into solvable emotional problems.
2022-04-26 05:32:07 | INFO | fairseq.tasks.translation | example hypothesis: and we said, "UNKNOWNTOKENINHYP, you know," we said, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you
2022-04-26 05:32:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at UNKNOWNTOKENINREF women is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-04-26 05:32:08 | INFO | fairseq.tasks.translation | example hypothesis: this is the first time that we've been able to use this technology to detect UNKNOWNTOKENINHYP, and we've been able to use this technology to detect UNKNOWNTOKENINHYP, to detect UNKNOWNTOKENINHYP, to detect UNKNOWNTOKENINHYP, to detect UNKNOWNTOKENINHYP, to detect UNKNOWNTOKENINHYP, to detect UNKNOWNTOKENINHYP.
2022-04-26 05:32:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of UNKNOWNTOKENINREF, and a lot of the design work that we're the most proud of with the aircraft came out of UNKNOWNTOKENINREF the unique problems of operating it on the ground -- everything from a continuouslUNKNOWNTOKENINREF variable transmission and liquiUNKNOWNTOKENINREF based cooling system that allows us to use an aircraft engine in stop-UNKNOWNTOKENINREF go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wUNKNOWNTOKENINREF folding mechanism that we'll see in a moment, to crash safety features.
2022-04-26 05:32:08 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.631 | nll_loss 5.182 | ppl 36.31 | bleu 1.87 | wps 1580.7 | wpb 2835.3 | bsz 115.6 | num_updates 1102
2022-04-26 05:32:08 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-04-26 05:32:08 | INFO | train | epoch 001 | loss 7.818 | nll_loss 6.307 | ppl 79.16 | wps 5685.3 | ups 1.59 | wpb 3583.6 | bsz 145.4 | num_updates 1102 | lr 0.00013775 | gnorm 15.256 | train_wall 573 | gb_free 6.9 | wall 695
2022-04-26 05:32:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2022-04-26 05:32:08 | INFO | fairseq.trainer | begin training epoch 2
2022-04-26 05:32:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-04-26 05:33:01 | INFO | train_inner | epoch 002:     98 / 1102 loss=6.689, nll_loss=5.24, ppl=37.8, wps=2177.9, ups=0.6, wpb=3647.1, bsz=162.7, num_updates=1200, lr=0.00015, gnorm=15.956, train_wall=53, gb_free=6.1, wall=748
2022-04-26 05:33:55 | INFO | train_inner | epoch 002:    198 / 1102 loss=6.62, nll_loss=5.194, ppl=36.61, wps=6636.6, ups=1.85, wpb=3585.3, bsz=143.4, num_updates=1300, lr=0.0001625, gnorm=9.594, train_wall=53, gb_free=6.6, wall=802
2022-04-26 05:34:49 | INFO | train_inner | epoch 002:    298 / 1102 loss=6.625, nll_loss=5.192, ppl=36.57, wps=6610.8, ups=1.87, wpb=3535.2, bsz=156.3, num_updates=1400, lr=0.000175, gnorm=14.67, train_wall=53, gb_free=6.3, wall=856
2022-04-26 05:35:42 | INFO | train_inner | epoch 002:    398 / 1102 loss=6.571, nll_loss=5.155, ppl=35.62, wps=6668.2, ups=1.87, wpb=3571.4, bsz=133.5, num_updates=1500, lr=0.0001875, gnorm=9.196, train_wall=53, gb_free=6.5, wall=910
2022-04-26 05:36:36 | INFO | train_inner | epoch 002:    498 / 1102 loss=6.519, nll_loss=5.097, ppl=34.23, wps=6717.9, ups=1.86, wpb=3605.1, bsz=141, num_updates=1600, lr=0.0002, gnorm=10.001, train_wall=53, gb_free=6.1, wall=963
2022-04-26 05:37:30 | INFO | train_inner | epoch 002:    598 / 1102 loss=6.564, nll_loss=5.12, ppl=34.77, wps=6734.1, ups=1.87, wpb=3594.6, bsz=147, num_updates=1700, lr=0.0002125, gnorm=13.244, train_wall=53, gb_free=6.3, wall=1017
2022-04-26 05:38:23 | INFO | train_inner | epoch 002:    698 / 1102 loss=6.515, nll_loss=5.055, ppl=33.24, wps=6609.2, ups=1.86, wpb=3545.2, bsz=151.7, num_updates=1800, lr=0.000225, gnorm=11.12, train_wall=53, gb_free=6.5, wall=1070
2022-04-26 05:39:17 | INFO | train_inner | epoch 002:    798 / 1102 loss=6.437, nll_loss=4.998, ppl=31.95, wps=6716.6, ups=1.87, wpb=3598.2, bsz=145.5, num_updates=1900, lr=0.0002375, gnorm=11.322, train_wall=53, gb_free=6.2, wall=1124
2022-04-26 05:40:10 | INFO | train_inner | epoch 002:    898 / 1102 loss=6.459, nll_loss=5.036, ppl=32.8, wps=6784, ups=1.88, wpb=3612.1, bsz=136.8, num_updates=2000, lr=0.00025, gnorm=10.18, train_wall=52, gb_free=6.4, wall=1177
2022-04-26 05:41:03 | INFO | train_inner | epoch 002:    998 / 1102 loss=6.416, nll_loss=4.985, ppl=31.67, wps=6582.7, ups=1.87, wpb=3517, bsz=142.6, num_updates=2100, lr=0.0002625, gnorm=11.668, train_wall=53, gb_free=6.4, wall=1230
2022-04-26 05:41:57 | INFO | train_inner | epoch 002:   1098 / 1102 loss=6.443, nll_loss=5.012, ppl=32.27, wps=6785.8, ups=1.87, wpb=3621.5, bsz=140.6, num_updates=2200, lr=0.000275, gnorm=11.728, train_wall=53, gb_free=6, wall=1284
2022-04-26 05:41:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-04-26 05:42:01 | INFO | fairseq.tasks.translation | example hypothesis: they don't just look at them, they look at them.
2022-04-26 05:42:01 | INFO | fairseq.tasks.translation | example reference: they're just not moving.
2022-04-26 05:42:03 | INFO | fairseq.tasks.translation | example hypothesis: then i said, "what?" and then i said, "what?"
2022-04-26 05:42:03 | INFO | fairseq.tasks.translation | example reference: i was like "what?"
2022-04-26 05:42:05 | INFO | fairseq.tasks.translation | example hypothesis: all right? no, no, no, no, no, no, no.
2022-04-26 05:42:05 | INFO | fairseq.tasks.translation | example reference: is it all worked out? no.
2022-04-26 05:42:07 | INFO | fairseq.tasks.translation | example hypothesis: we need to have more.
2022-04-26 05:42:07 | INFO | fairseq.tasks.translation | example reference: we need to use less to make more.
2022-04-26 05:42:08 | INFO | fairseq.tasks.translation | example hypothesis: but let's go back to the mayor of mayor mayor mayor mayor.
2022-04-26 05:42:08 | INFO | fairseq.tasks.translation | example reference: but homage to singUNKNOWNTOKENINREF re.
2022-04-26 05:42:10 | INFO | fairseq.tasks.translation | example hypothesis: we call it "UNKNOWNTOKENINHYP." we call it "UNKNOWNTOKENINHYP."
2022-04-26 05:42:10 | INFO | fairseq.tasks.translation | example reference: we call this UNKNOWNTOKENINREF tational lensing.
2022-04-26 05:42:12 | INFO | fairseq.tasks.translation | example hypothesis: now think about it, think about it.
2022-04-26 05:42:12 | INFO | fairseq.tasks.translation | example reference: well, consider by UNKNOWNTOKENINREF y, the concept of physical health.
2022-04-26 05:42:14 | INFO | fairseq.tasks.translation | example hypothesis: these are the people who are going to be able to UNKNOWNTOKENINHYP te with the people who are going to be able to UNKNOWNTOKENINHYP te.
2022-04-26 05:42:14 | INFO | fairseq.tasks.translation | example reference: these are the classic conditions that create regret.
2022-04-26 05:42:16 | INFO | fairseq.tasks.translation | example hypothesis: or, you know, it's really, really hard to think about what's going on or what's not.
2022-04-26 05:42:16 | INFO | fairseq.tasks.translation | example reference: valence means good or bad, positive or negative.
2022-04-26 05:42:17 | INFO | fairseq.tasks.translation | example hypothesis: it's the only way that it's going to happen.
2022-04-26 05:42:17 | INFO | fairseq.tasks.translation | example reference: the bad news is they're rocket fuels.
2022-04-26 05:42:19 | INFO | fairseq.tasks.translation | example hypothesis: it can be able to be able to be able to be able to be able to be able to be able to be able to do it.
2022-04-26 05:42:19 | INFO | fairseq.tasks.translation | example reference: it can be used for calculating UNKNOWNTOKENINREF equations of all different types.
2022-04-26 05:42:21 | INFO | fairseq.tasks.translation | example hypothesis: we should be able to do that, and we should be able to do that, and we should be able to do that.
2022-04-26 05:42:21 | INFO | fairseq.tasks.translation | example reference: we should probably slow down, and that point of action is probably now.
2022-04-26 05:42:23 | INFO | fairseq.tasks.translation | example hypothesis: we're going to use it, and we're going to use it, and we're going to use it.
2022-04-26 05:42:23 | INFO | fairseq.tasks.translation | example reference: decided to use UNKNOWNTOKENINREF ed content from cement and steel manufacturing.
2022-04-26 05:42:25 | INFO | fairseq.tasks.translation | example hypothesis: in the last two years, we've only been able to look at the last two years.
2022-04-26 05:42:25 | INFO | fairseq.tasks.translation | example reference: just in the last two days, we got the new temperature UNKNOWNTOKENINREF ds in UNKNOWNTOKENINREF ary.
2022-04-26 05:42:27 | INFO | fairseq.tasks.translation | example hypothesis: this is something that's really important to think about.
2022-04-26 05:42:27 | INFO | fairseq.tasks.translation | example reference: and to remind you that here is an example in which architecture actually did something.
2022-04-26 05:42:28 | INFO | fairseq.tasks.translation | example hypothesis: this woman has never seen this woman, she has never seen this woman.
2022-04-26 05:42:28 | INFO | fairseq.tasks.translation | example reference: and the grandmother had never let any westerners ever see her.
2022-04-26 05:42:30 | INFO | fairseq.tasks.translation | example hypothesis: so this is something that we don't know about.
2022-04-26 05:42:30 | INFO | fairseq.tasks.translation | example reference: this is something we've actually known for a while, so it's not a real breakthrough.
2022-04-26 05:42:32 | INFO | fairseq.tasks.translation | example hypothesis: it's almost as if you're living in a rural village, you're living in a rural village.
2022-04-26 05:42:32 | INFO | fairseq.tasks.translation | example reference: it's a social awkwardness like you're a stranger in a foreign land.
2022-04-26 05:42:34 | INFO | fairseq.tasks.translation | example hypothesis: i had to learn how to learn how to learn to learn to learn to learn to learn to learn to learn to learn to learn to learn to learn to learn.
2022-04-26 05:42:34 | INFO | fairseq.tasks.translation | example reference: i had learned to read music by then, or slowly learning to read music.
2022-04-26 05:42:36 | INFO | fairseq.tasks.translation | example hypothesis: they said, "we don't have to worry about it.
2022-04-26 05:42:36 | INFO | fairseq.tasks.translation | example reference: they said they were going to beat us up if we didn't make some gunpowder for them.
2022-04-26 05:42:37 | INFO | fairseq.tasks.translation | example hypothesis: now, what we're going to do now is we're going to take a little bit of information, we're going to take a little bit of information.
2022-04-26 05:42:37 | INFO | fairseq.tasks.translation | example reference: well, we collect data from satellites, from airplanes, from ground UNKNOWNTOKENINREF cles, from people.
2022-04-26 05:42:39 | INFO | fairseq.tasks.translation | example hypothesis: and with all these women who had been through this journey, and with all these women who had been through this journey, and with all these women who had been through this journey, and with
2022-04-26 05:42:39 | INFO | fairseq.tasks.translation | example reference: and one of the UNKNOWNTOKENINREF things that happened was this act of actually connecting to all these people.
2022-04-26 05:42:41 | INFO | fairseq.tasks.translation | example hypothesis: i want to share with you a story with you.
2022-04-26 05:42:41 | INFO | fairseq.tasks.translation | example reference: i want to share one story about an innovation called drip irriUNKNOWNTOKENINREF.
2022-04-26 05:42:43 | INFO | fairseq.tasks.translation | example hypothesis: this woman, who was the youngest boy, was the youngest boy, and this woman was the youngest boy, and this woman was the youngest boy.
2022-04-26 05:42:43 | INFO | fairseq.tasks.translation | example reference: the man, his name was mahmoud, and the child, whose name was rafi, left.
2022-04-26 05:42:44 | INFO | fairseq.tasks.translation | example hypothesis: and there's no way that it's going to be able to look at the brain without looking at the brain.
2022-04-26 05:42:44 | INFO | fairseq.tasks.translation | example reference: and that allows me to check my timer discretely, here, without bending my elbow.
2022-04-26 05:42:46 | INFO | fairseq.tasks.translation | example hypothesis: in our own backyard, we had our own version of our own version of our own.
2022-04-26 05:42:46 | INFO | fairseq.tasks.translation | example reference: she arrived at our reserve from a reserve east of us on her UNKNOWNTOKENINREF atory route.
2022-04-26 05:42:48 | INFO | fairseq.tasks.translation | example hypothesis: if we can get to the top of the mountain, if we can get to the top of the mountain, we can get to the top of the mountain.
2022-04-26 05:42:48 | INFO | fairseq.tasks.translation | example reference: if we can make it through the next 150 years, i think that your great great grandchildren will forget all about malthus.
2022-04-26 05:42:49 | INFO | fairseq.tasks.translation | example hypothesis: and with this little bit of technology, we're able to UNKNOWNTOKENINHYP with these little bit of technology, and with this little bit of technology, we're able to UNKNOWNTOKENINHYP with these little bit of technology.
2022-04-26 05:42:49 | INFO | fairseq.tasks.translation | example reference: those are then selected by the UNKNOWNTOKENINREF m, reproduced with mutation and reUNKNOWNTOKENINREF ations to introduce sex as well.
2022-04-26 05:42:51 | INFO | fairseq.tasks.translation | example hypothesis: but it's not really where you should be, it's where you should be.
2022-04-26 05:42:51 | INFO | fairseq.tasks.translation | example reference: now, it just shouldn't take these sorts of efforts to find out where the money in deals like this went.
2022-04-26 05:42:53 | INFO | fairseq.tasks.translation | example hypothesis: if you don't have the resources, if you don't have the resources, if you don't have the resources, if you don't have the resources.
2022-04-26 05:42:53 | INFO | fairseq.tasks.translation | example reference: when people don't take their pills, when people don't follow doctors' orders -- these are behavior problems.
2022-04-26 05:42:54 | INFO | fairseq.tasks.translation | example hypothesis: so if you think about it, there are many different ways of thinking about it.
2022-04-26 05:42:54 | INFO | fairseq.tasks.translation | example reference: so it's pretty sad to find that UNKNOWNTOKENINREF es, like so many other UNKNOWNTOKENINREF around the world, are losing their habitats.
2022-04-26 05:42:56 | INFO | fairseq.tasks.translation | example hypothesis: we're going to show you a couple of examples of this, and we're going to show you a couple of examples of this, and we're going to show you a couple of examples of this.
2022-04-26 05:42:56 | INFO | fairseq.tasks.translation | example reference: we discovered bluegrass a few years ago, and we fell in love with it. we hope you guys will too.
2022-04-26 05:42:58 | INFO | fairseq.tasks.translation | example hypothesis: so what i'm going to do is we're going to have a system that can do it.
2022-04-26 05:42:58 | INFO | fairseq.tasks.translation | example reference: so i was trying to, you know, take the engineer's version: can we build a mechanical system in inorganic materials that will do the same thing?
2022-04-26 05:42:59 | INFO | fairseq.tasks.translation | example hypothesis: we have to ask ourselves, we have to ask ourselves, we have to ask ourselves, we have to ask ourselves, we have to ask ourselves, we have to ask ourselves.
2022-04-26 05:42:59 | INFO | fairseq.tasks.translation | example reference: we consult to the media about canopy questions; we have a canopy newsletter; we have an email listserv.
2022-04-26 05:43:01 | INFO | fairseq.tasks.translation | example hypothesis: and this is my wish today.
2022-04-26 05:43:01 | INFO | fairseq.tasks.translation | example reference: what my purpose of the talk today really is, is to sort of indelibly scar your minds with these charismatic and majestic UNKNOWNTOKENINREF.
2022-04-26 05:43:03 | INFO | fairseq.tasks.translation | example hypothesis: so if you look at it, if you look at it, if you look at it, if you look at it, if you look at it, if you look at it, if you look at it, if you look at it.
2022-04-26 05:43:03 | INFO | fairseq.tasks.translation | example reference: now, it's no surprise that when you add consecutive fibonacci numbers, you get the next fibonacci number. right?
2022-04-26 05:43:05 | INFO | fairseq.tasks.translation | example hypothesis: but we don't have to worry about it, we don't have to worry about it.
2022-04-26 05:43:05 | INFO | fairseq.tasks.translation | example reference: yet we dither, taking no action to deflect the UNKNOWNTOKENINREF id, even though the longer we wait, the more difficult and expensive it becomes. "
2022-04-26 05:43:06 | INFO | fairseq.tasks.translation | example hypothesis: he told me that he was a very clever man, he was a very clever man, he was a very clever man, he was very clever.
2022-04-26 05:43:06 | INFO | fairseq.tasks.translation | example reference: he had this amazing series of hairs growing out of a mole on the left side of his face, which i'm told is very good luck.
2022-04-26 05:43:08 | INFO | fairseq.tasks.translation | example hypothesis: this is the first example of a UNKNOWNTOKENINHYP e that's actually a UNKNOWNTOKENINHYP e that's a UNKNOWNTOKENINHYP e, and it's also a UNKNOWNTOKENINHYP e that's a UNKNOWNTOKENINHYP e that's a UNKNOWNTOKENINHYP e.
2022-04-26 05:43:08 | INFO | fairseq.tasks.translation | example reference: here's the first battery -- a stack of coins, zinc and silver, separated by cardboard soaked in brine.
2022-04-26 05:43:10 | INFO | fairseq.tasks.translation | example hypothesis: in fact, this is an example of this because of the fact that people who have been UNKNOWNTOKENINHYP cted in the past have been UNKNOWNTOKENINHYP cted in the past.
2022-04-26 05:43:10 | INFO | fairseq.tasks.translation | example reference: durkheim called this level the level of the sacred because he believed that the function of religion was to unite people into a group, into a moral community.
2022-04-26 05:43:11 | INFO | fairseq.tasks.translation | example hypothesis: but if you look at it, it's a little bit different.
2022-04-26 05:43:11 | INFO | fairseq.tasks.translation | example reference: but the UNKNOWNTOKENINREF match up if i rotate by a sixth of a turn around the point where all the trianUNKNOWNTOKENINREF meet.
2022-04-26 05:43:13 | INFO | fairseq.tasks.translation | example hypothesis: and if you look at it, you'll see that there's a lot of people who are doing this with their kids, and they're doing it with their kids.
2022-04-26 05:43:13 | INFO | fairseq.tasks.translation | example reference: there's little brochures all around outside, and if any of you have anything to do with children and care about their future, i beg that you pick up that brochure.
2022-04-26 05:43:15 | INFO | fairseq.tasks.translation | example hypothesis: and the only way to do this is to take a small number of cells, and only a small number of cells, and only a small number of cells, and only a small number of cells.
2022-04-26 05:43:15 | INFO | fairseq.tasks.translation | example reference: and this is only done in four hours, 50 times faster than the current state of the art, at a cost that will be five to 500 times cheaper than the current options.
2022-04-26 05:43:16 | INFO | fairseq.tasks.translation | example hypothesis: and if you look at what i'm talking about, what i'm talking about is, if you look at what i'm talking about, what i'm talking about, what i'm talking about.
2022-04-26 05:43:16 | INFO | fairseq.tasks.translation | example reference: i'm fascinated with the idea of what happens when you merge UNKNOWNTOKENINREF with technology, and i remember reading about this idea of being able to reprogram UNKNOWNTOKENINREF, in the future, away from disease and aging.
2022-04-26 05:43:18 | INFO | fairseq.tasks.translation | example hypothesis: but you know, it's really hard to find them, and it's really hard to find them.
2022-04-26 05:43:18 | INFO | fairseq.tasks.translation | example reference: but the problem with relying on rules and inUNKNOWNTOKENINREF ves is that they demorUNKNOWNTOKENINREF professional activity, and they demorUNKNOWNTOKENINREF professional activity in two UNKNOWNTOKENINREF.
2022-04-26 05:43:20 | INFO | fairseq.tasks.translation | example hypothesis: and i'm going to give you an example of what we're doing in UNKNOWNTOKENINHYP, and i'm going to give you an example of what we're doing in UNKNOWNTOKENINHYP, and i'm going to give you an example of what we're doing in UNKNOWNTOKENINHYP.
2022-04-26 05:43:20 | INFO | fairseq.tasks.translation | example reference: i belong to an internet discussion forum, an UNKNOWNTOKENINREF internet discussion forum, and i asked them, i said, "since 1960, we've had exactly 204 UNKNOWNTOKENINREF heads of state, since 1960."
2022-04-26 05:43:21 | INFO | fairseq.tasks.translation | example hypothesis: and i really think that it's really hard to find a way to do that, and it's really hard to find a way to do that.
2022-04-26 05:43:21 | INFO | fairseq.tasks.translation | example reference: and as these dark clouds were circling me, and i was finding it really, really difficult to think of anything good, i said to myself that i really needed a way to focus on the positive somehow.
2022-04-26 05:43:23 | INFO | fairseq.tasks.translation | example hypothesis: you know, it's a little bit different, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know.
2022-04-26 05:43:23 | INFO | fairseq.tasks.translation | example reference: for example, gUNKNOWNTOKENINREF age discharge, something you would think just simply goes away, but the laws regulating ship discharge of gUNKNOWNTOKENINREF age actually get weaker the further you are from shore.
2022-04-26 05:43:24 | INFO | fairseq.tasks.translation | example hypothesis: so he was able to take a little bit of this little bit of this little bit of this little bit of this little bit of this little bit of this little bit of this little bit of this little bit of this little bit of this little bit of this little bit of this little bit of this little bit of this little bit of this little bit of it.
2022-04-26 05:43:24 | INFO | fairseq.tasks.translation | example reference: see, he owned a UNKNOWNTOKENINREF mium plating company, and they had to move heavy steel parts between tanks of chemicals, and so he needed an industrial robot like this that could basically do the heavy lifting.
2022-04-26 05:43:26 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, the women who have sex with their mothers have sex with their mothers with their fathers.
2022-04-26 05:43:26 | INFO | fairseq.tasks.translation | example reference: and the religious police imposes the supposed UNKNOWNTOKENINREF ic way of life on every citizen, by force -- like women are forced to cover their heads -- wear the hijab, the UNKNOWNTOKENINREF ic head cover.
2022-04-26 05:43:28 | INFO | fairseq.tasks.translation | example hypothesis: and when you look around the world, you'll see that there's a huge difference between men and women.
2022-04-26 05:43:28 | INFO | fairseq.tasks.translation | example reference: come with me to the bottom of the world, antUNKNOWNTOKENINREF tica, the highest, driest, windiest, and yes, coldest region on earth -- more arid than the UNKNOWNTOKENINREF a and, in parts, colder than UNKNOWNTOKENINREF.
2022-04-26 05:43:29 | INFO | fairseq.tasks.translation | example hypothesis: so here's my favorite example of how you can see it.
2022-04-26 05:43:29 | INFO | fairseq.tasks.translation | example reference: that's kellar autumn, my former ph.d. student, professor now at lewis and clark, literally giving his firUNKNOWNTOKENINREF born child up for this test.
2022-04-26 05:43:31 | INFO | fairseq.tasks.translation | example hypothesis: it's the only way we think of ourselves, and it's the only way we think of ourselves, and it's the only way we think of ourselves, and it's the only way we think of ourselves.
2022-04-26 05:43:31 | INFO | fairseq.tasks.translation | example reference: however, while it's easier to think of us, the citizens, the police, the army, as the good guys, and them, the narcos, the carteles, as the bad guys, if you think about it, the latter are only providing a service to the former.
2022-04-26 05:43:33 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, i've been working on this for a long time, and i've been working on this for a long time.
2022-04-26 05:43:33 | INFO | fairseq.tasks.translation | example reference: and for the following 25 years, living in italy, living in UNKNOWNTOKENINREF, i doled out a piece of this romance to anybody who'd pay for it -- this sense, this aesthetic feeling, for the experience revolving around a designed object.
2022-04-26 05:43:34 | INFO | fairseq.tasks.translation | example hypothesis: but we don't have to worry about that, because we've done a lot of research on this, and we've done a lot of research on this.
2022-04-26 05:43:34 | INFO | fairseq.tasks.translation | example reference: because we've UNKNOWNTOKENINREF the problem in chubut province, which is like a state in argentina where punta tombo is -- so that's about 1,000 UNKNOWNTOKENINREF of coastline -- but we haven't UNKNOWNTOKENINREF the problem in northern argentina, uruguay and UNKNOWNTOKENINREF.
2022-04-26 05:43:36 | INFO | fairseq.tasks.translation | example hypothesis: and we said, "well, you know, you know, we're going to take a little bit of water, and we're going to take a little bit of water."
2022-04-26 05:43:36 | INFO | fairseq.tasks.translation | example reference: animal fan nellie mckay sings a sparkling UNKNOWNTOKENINREF te to her dear dog. she suggests we all do the same: "just go right to the pound / and find yourself a hound / and make that doggie proud / 'cause that's what it's all about."
2022-04-26 05:43:37 | INFO | fairseq.tasks.translation | example hypothesis: and it turns out there's a whole bunch of studies that have been done by scientists around the world, and it's been done by scientists around the world.
2022-04-26 05:43:37 | INFO | fairseq.tasks.translation | example reference: with streams and rivers drying up because of over-usage, rob harmon has UNKNOWNTOKENINREF mented an ingenious market mechanism to bring back the water. farmers and beer companies find their fates intertwined in the intriguing centurUNKNOWNTOKENINREF old tale of prickly pear creek. & lt; em & gt; & lt; / em & gt;
2022-04-26 05:43:39 | INFO | fairseq.tasks.translation | example hypothesis: and we don't have to worry about it, we don't have to worry about it, we don't have to worry about it, we don't have to worry about it.
2022-04-26 05:43:39 | INFO | fairseq.tasks.translation | example reference: and the reality of the society that we're in is there are thousands and thousands of people out there leading lives of quiet, screaming desperation, where they work long, hard hours at jobs they hate to enable them to buy things they don't need to impress people they don't like.
2022-04-26 05:43:40 | INFO | fairseq.tasks.translation | example hypothesis: and i'm going to give you a little bit of a sense of what we're doing, and it's a little bit of a sense of what we're doing, and it's a little bit of a sense of what we're doing.
2022-04-26 05:43:40 | INFO | fairseq.tasks.translation | example reference: and i organize it. and, well, it's also a bit different because an UNKNOWNTOKENINREF versus, let's say, a dance company finally is a negotiation between one's private world, one's UNKNOWNTOKENINREF tual world, the world of ideas, the world of aspirations, of UNKNOWNTOKENINREF tions, with the relationship of the exterior world and all the limitations, the naysayers.
2022-04-26 05:43:42 | INFO | fairseq.tasks.translation | example hypothesis: and this is what we're doing, and this is what we're doing, and this is what we're doing, and this is what we're doing, and this is what we're doing.
2022-04-26 05:43:42 | INFO | fairseq.tasks.translation | example reference: and i also hope that you share the idea that if engineers and UNKNOWNTOKENINREF can use all these different climatic parameters, it will be possible to create really good and comfortable outdoor conditions, to change our thermal perception that we feel comfortable in an outdoor environment, and we can do that with the best passive design, but also using the energy source of the site in qatar which is the sun.
2022-04-26 05:43:44 | INFO | fairseq.tasks.translation | example hypothesis: and i remember thinking, well, you know, it was a little bit of a surprise to me, and it was a little bit of a surprise.
2022-04-26 05:43:44 | INFO | fairseq.tasks.translation | example reference: i used to say that these people saved me, but what i now know is they did something even more important in that they empowered me to save myself, and crucially, they helped me to understand something which i'd always UNKNOWNTOKENINREF pected: that my voices were a meaningful response to traumatic life events, particularly childhood events, and as such were not my enemies but a source of insight into solvable emotional problems.
2022-04-26 05:43:44 | INFO | fairseq.tasks.translation | example hypothesis: for example, if you think about it, it's a little bit like saying, "UNKNOWNTOKENINHYP, you know, we've got to go back to UNKNOWNTOKENINHYP, we've got to go back to UNKNOWNTOKENINHYP."
2022-04-26 05:43:44 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at UNKNOWNTOKENINREF women is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-04-26 05:43:45 | INFO | fairseq.tasks.translation | example hypothesis: so if you look at it, you'll see that there's a little bit of an overwhelmed sense of what we're doing, and it's a little bit of an overwhelmed sense of what we're doing, and it's a little bit of an overwhelmed sense of what we're doing.
2022-04-26 05:43:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of UNKNOWNTOKENINREF, and a lot of the design work that we're the most proud of with the aircraft came out of UNKNOWNTOKENINREF the unique problems of operating it on the ground -- everything from a continuouslUNKNOWNTOKENINREF variable transmission and liquiUNKNOWNTOKENINREF based cooling system that allows us to use an aircraft engine in stop-UNKNOWNTOKENINREF go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wUNKNOWNTOKENINREF folding mechanism that we'll see in a moment, to crash safety features.
2022-04-26 05:43:45 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 6.228 | nll_loss 4.819 | ppl 28.23 | bleu 3.19 | wps 1695.5 | wpb 2835.3 | bsz 115.6 | num_updates 2204
2022-04-26 05:43:45 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-04-26 05:43:45 | INFO | train | epoch 002 | loss 6.533 | nll_loss 5.099 | ppl 34.27 | wps 5668.1 | ups 1.58 | wpb 3583.6 | bsz 145.4 | num_updates 2204 | lr 0.0002755 | gnorm 11.697 | train_wall 582 | gb_free 6.3 | wall 1392
2022-04-26 05:43:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2022-04-26 05:43:45 | INFO | fairseq.trainer | begin training epoch 3
2022-04-26 05:43:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-04-26 05:44:37 | INFO | train_inner | epoch 003:     96 / 1102 loss=6.114, nll_loss=4.666, ppl=25.38, wps=2247.7, ups=0.62, wpb=3598.2, bsz=139, num_updates=2300, lr=0.0002875, gnorm=6.925, train_wall=53, gb_free=6.3, wall=1444
2022-04-26 05:45:31 | INFO | train_inner | epoch 003:    196 / 1102 loss=6.173, nll_loss=4.711, ppl=26.2, wps=6561.4, ups=1.85, wpb=3550.9, bsz=140.2, num_updates=2400, lr=0.0003, gnorm=10.246, train_wall=53, gb_free=6.5, wall=1498
2022-04-26 05:46:25 | INFO | train_inner | epoch 003:    296 / 1102 loss=6.228, nll_loss=4.753, ppl=26.96, wps=6710.8, ups=1.87, wpb=3598, bsz=144, num_updates=2500, lr=0.0003125, gnorm=13.514, train_wall=53, gb_free=5.9, wall=1552
2022-04-26 05:47:18 | INFO | train_inner | epoch 003:    396 / 1102 loss=6.118, nll_loss=4.657, ppl=25.22, wps=6719.5, ups=1.86, wpb=3612.2, bsz=145.7, num_updates=2600, lr=0.000325, gnorm=6.982, train_wall=53, gb_free=6.5, wall=1605
2022-04-26 05:48:12 | INFO | train_inner | epoch 003:    496 / 1102 loss=6.277, nll_loss=4.789, ppl=27.65, wps=6703.1, ups=1.86, wpb=3607, bsz=134.4, num_updates=2700, lr=0.0003375, gnorm=10.736, train_wall=53, gb_free=7.4, wall=1659
2022-04-26 05:49:05 | INFO | train_inner | epoch 003:    596 / 1102 loss=6.099, nll_loss=4.647, ppl=25.05, wps=6605.3, ups=1.88, wpb=3514.6, bsz=151.8, num_updates=2800, lr=0.00035, gnorm=6.276, train_wall=52, gb_free=6.1, wall=1712
2022-04-26 05:49:59 | INFO | train_inner | epoch 003:    696 / 1102 loss=6.207, nll_loss=4.73, ppl=26.54, wps=6663.1, ups=1.85, wpb=3603.9, bsz=158.3, num_updates=2900, lr=0.0003625, gnorm=9.645, train_wall=53, gb_free=6.3, wall=1767
2022-04-26 05:50:53 | INFO | train_inner | epoch 003:    796 / 1102 loss=6.122, nll_loss=4.671, ppl=25.47, wps=6705.7, ups=1.87, wpb=3595, bsz=153.6, num_updates=3000, lr=0.000375, gnorm=7.204, train_wall=53, gb_free=6.5, wall=1820
2022-04-26 05:51:47 | INFO | train_inner | epoch 003:    896 / 1102 loss=6.229, nll_loss=4.805, ppl=27.96, wps=6621.6, ups=1.87, wpb=3547.3, bsz=121.1, num_updates=3100, lr=0.0003875, gnorm=5.226, train_wall=53, gb_free=6.5, wall=1874
2022-04-26 05:52:40 | INFO | train_inner | epoch 003:    996 / 1102 loss=6.269, nll_loss=4.791, ppl=27.68, wps=6792.6, ups=1.87, wpb=3628.6, bsz=150.8, num_updates=3200, lr=0.0004, gnorm=10.252, train_wall=53, gb_free=6.3, wall=1927
2022-04-26 05:53:33 | INFO | train_inner | epoch 003:   1096 / 1102 loss=6.201, nll_loss=4.758, ppl=27.06, wps=6701, ups=1.88, wpb=3561.8, bsz=158.9, num_updates=3300, lr=0.0004125, gnorm=8.697, train_wall=52, gb_free=6.4, wall=1980
2022-04-26 05:53:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-04-26 05:53:38 | INFO | fairseq.tasks.translation | example hypothesis: you just don't let it go.
2022-04-26 05:53:38 | INFO | fairseq.tasks.translation | example reference: they're just not moving.
2022-04-26 05:53:39 | INFO | fairseq.tasks.translation | example hypothesis: so what do i do? "
2022-04-26 05:53:39 | INFO | fairseq.tasks.translation | example reference: i was like "what?"
2022-04-26 05:53:41 | INFO | fairseq.tasks.translation | example hypothesis: does it work? no.
2022-04-26 05:53:41 | INFO | fairseq.tasks.translation | example reference: is it all worked out? no.
2022-04-26 05:53:42 | INFO | fairseq.tasks.translation | example hypothesis: we need to make more money.
2022-04-26 05:53:42 | INFO | fairseq.tasks.translation | example reference: we need to use less to make more.
2022-04-26 05:53:43 | INFO | fairseq.tasks.translation | example hypothesis: but matt mills: okay.
2022-04-26 05:53:43 | INFO | fairseq.tasks.translation | example reference: but homage to singUNKNOWNTOKENINREF re.
2022-04-26 05:53:44 | INFO | fairseq.tasks.translation | example hypothesis: we call it the UNKNOWNTOKENINHYP.
2022-04-26 05:53:44 | INFO | fairseq.tasks.translation | example reference: we call this UNKNOWNTOKENINREF tational lensing.
2022-04-26 05:53:46 | INFO | fairseq.tasks.translation | example hypothesis: think about how human UNKNOWNTOKENINHYP think.
2022-04-26 05:53:46 | INFO | fairseq.tasks.translation | example reference: well, consider by UNKNOWNTOKENINREF y, the concept of physical health.
2022-04-26 05:53:47 | INFO | fairseq.tasks.translation | example hypothesis: these are the key tools that we use to solve these problems.
2022-04-26 05:53:47 | INFO | fairseq.tasks.translation | example reference: these are the classic conditions that create regret.
2022-04-26 05:53:48 | INFO | fairseq.tasks.translation | example hypothesis: good, bad, bad, bad.
2022-04-26 05:53:48 | INFO | fairseq.tasks.translation | example reference: valence means good or bad, positive or negative.
2022-04-26 05:53:50 | INFO | fairseq.tasks.translation | example hypothesis: the bad news is that it's cheap.
2022-04-26 05:53:50 | INFO | fairseq.tasks.translation | example reference: the bad news is they're rocket fuels.
2022-04-26 05:53:51 | INFO | fairseq.tasks.translation | example hypothesis: it can be used as a mechanical mechanism.
2022-04-26 05:53:51 | INFO | fairseq.tasks.translation | example reference: it can be used for calculating UNKNOWNTOKENINREF equations of all different types.
2022-04-26 05:53:52 | INFO | fairseq.tasks.translation | example hypothesis: maybe we should be doing that, and we should be doing that.
2022-04-26 05:53:52 | INFO | fairseq.tasks.translation | example reference: we should probably slow down, and that point of action is probably now.
2022-04-26 05:53:54 | INFO | fairseq.tasks.translation | example hypothesis: we decided that we would build the first building in UNKNOWNTOKENINHYP and build the first building in UNKNOWNTOKENINHYP.
2022-04-26 05:53:54 | INFO | fairseq.tasks.translation | example reference: decided to use UNKNOWNTOKENINREF ed content from cement and steel manufacturing.
2022-04-26 05:53:55 | INFO | fairseq.tasks.translation | example hypothesis: the last two months of the last two months of the last two months of the last two months of the last two months of the last month of the last
2022-04-26 05:53:55 | INFO | fairseq.tasks.translation | example reference: just in the last two days, we got the new temperature UNKNOWNTOKENINREF ds in UNKNOWNTOKENINREF ary.
2022-04-26 05:53:56 | INFO | fairseq.tasks.translation | example hypothesis: and this is actually an example of what's going on.
2022-04-26 05:53:56 | INFO | fairseq.tasks.translation | example reference: and to remind you that here is an example in which architecture actually did something.
2022-04-26 05:53:58 | INFO | fairseq.tasks.translation | example hypothesis: those of you who didn't know this were never seen again.
2022-04-26 05:53:58 | INFO | fairseq.tasks.translation | example reference: and the grandmother had never let any westerners ever see her.
2022-04-26 05:53:59 | INFO | fairseq.tasks.translation | example hypothesis: so we don't know what's going on.
2022-04-26 05:53:59 | INFO | fairseq.tasks.translation | example reference: this is something we've actually known for a while, so it's not a real breakthrough.
2022-04-26 05:54:00 | INFO | fairseq.tasks.translation | example hypothesis: it's as if you're a social organization.
2022-04-26 05:54:00 | INFO | fairseq.tasks.translation | example reference: it's a social awkwardness like you're a stranger in a foreign land.
2022-04-26 05:54:02 | INFO | fairseq.tasks.translation | example hypothesis: i learned how to learn.
2022-04-26 05:54:02 | INFO | fairseq.tasks.translation | example reference: i had learned to read music by then, or slowly learning to read music.
2022-04-26 05:54:03 | INFO | fairseq.tasks.translation | example hypothesis: they said, well, we didn't know why we were doing this.
2022-04-26 05:54:03 | INFO | fairseq.tasks.translation | example reference: they said they were going to beat us up if we didn't make some gunpowder for them.
2022-04-26 05:54:04 | INFO | fairseq.tasks.translation | example hypothesis: now, let's look at the data from UNKNOWNTOKENINHYP.
2022-04-26 05:54:04 | INFO | fairseq.tasks.translation | example reference: well, we collect data from satellites, from airplanes, from ground UNKNOWNTOKENINREF cles, from people.
2022-04-26 05:54:05 | INFO | fairseq.tasks.translation | example hypothesis: and one of the things that happened with this machine was the ability of the machine, the ability of the machine, the ability of the machine.
2022-04-26 05:54:05 | INFO | fairseq.tasks.translation | example reference: and one of the UNKNOWNTOKENINREF things that happened was this act of actually connecting to all these people.
2022-04-26 05:54:07 | INFO | fairseq.tasks.translation | example hypothesis: i'm going to share with you a story about this.
2022-04-26 05:54:07 | INFO | fairseq.tasks.translation | example reference: i want to share one story about an innovation called drip irriUNKNOWNTOKENINREF.
2022-04-26 05:54:08 | INFO | fairseq.tasks.translation | example hypothesis: his name was UNKNOWNTOKENINHYP, and he was this guy, and he was this guy.
2022-04-26 05:54:08 | INFO | fairseq.tasks.translation | example reference: the man, his name was mahmoud, and the child, whose name was rafi, left.
2022-04-26 05:54:10 | INFO | fairseq.tasks.translation | example hypothesis: and here's what you see on the screen.
2022-04-26 05:54:10 | INFO | fairseq.tasks.translation | example reference: and that allows me to check my timer discretely, here, without bending my elbow.
2022-04-26 05:54:11 | INFO | fairseq.tasks.translation | example hypothesis: we had our breakfast in the middle of the night.
2022-04-26 05:54:11 | INFO | fairseq.tasks.translation | example reference: she arrived at our reserve from a reserve east of us on her UNKNOWNTOKENINREF atory route.
2022-04-26 05:54:12 | INFO | fairseq.tasks.translation | example hypothesis: when we think about our future, we can think of our future as being unsustainable.
2022-04-26 05:54:12 | INFO | fairseq.tasks.translation | example reference: if we can make it through the next 150 years, i think that your great great grandchildren will forget all about malthus.
2022-04-26 05:54:14 | INFO | fairseq.tasks.translation | example hypothesis: it's made of UNKNOWNTOKENINHYP, and it's made of UNKNOWNTOKENINHYP, and it's made of UNKNOWNTOKENINHYP.
2022-04-26 05:54:14 | INFO | fairseq.tasks.translation | example reference: those are then selected by the UNKNOWNTOKENINREF m, reproduced with mutation and reUNKNOWNTOKENINREF ations to introduce sex as well.
2022-04-26 05:54:15 | INFO | fairseq.tasks.translation | example hypothesis: he wanted it to be easy, not hard, not hard, not hard.
2022-04-26 05:54:15 | INFO | fairseq.tasks.translation | example reference: now, it just shouldn't take these sorts of efforts to find out where the money in deals like this went.
2022-04-26 05:54:16 | INFO | fairseq.tasks.translation | example hypothesis: if you don't have your hand, you're not going to have your hand.
2022-04-26 05:54:16 | INFO | fairseq.tasks.translation | example reference: when people don't take their pills, when people don't follow doctors' orders -- these are behavior problems.
2022-04-26 05:54:17 | INFO | fairseq.tasks.translation | example hypothesis: how many of you know about the world, how many of you know about the world, how many of you know about the world.
2022-04-26 05:54:17 | INFO | fairseq.tasks.translation | example reference: so it's pretty sad to find that UNKNOWNTOKENINREF es, like so many other UNKNOWNTOKENINREF around the world, are losing their habitats.
2022-04-26 05:54:19 | INFO | fairseq.tasks.translation | example hypothesis: we've made a lot of mistakes, and we've made a lot of mistakes in the last couple of years.
2022-04-26 05:54:19 | INFO | fairseq.tasks.translation | example reference: we discovered bluegrass a few years ago, and we fell in love with it. we hope you guys will too.
2022-04-26 05:54:20 | INFO | fairseq.tasks.translation | example hypothesis: so what we need to do is to build a model of the system.
2022-04-26 05:54:20 | INFO | fairseq.tasks.translation | example reference: so i was trying to, you know, take the engineer's version: can we build a mechanical system in inorganic materials that will do the same thing?
2022-04-26 05:54:21 | INFO | fairseq.tasks.translation | example hypothesis: we've talked a little bit about what we're doing with the digital revolution.
2022-04-26 05:54:21 | INFO | fairseq.tasks.translation | example reference: we consult to the media about canopy questions; we have a canopy newsletter; we have an email listserv.
2022-04-26 05:54:23 | INFO | fairseq.tasks.translation | example hypothesis: this is what i want to talk about today.
2022-04-26 05:54:23 | INFO | fairseq.tasks.translation | example reference: what my purpose of the talk today really is, is to sort of indelibly scar your minds with these charismatic and majestic UNKNOWNTOKENINREF.
2022-04-26 05:54:24 | INFO | fairseq.tasks.translation | example hypothesis: so it turns out that if you look at the data, it turns out that it's not the same data, it turns out that it's not the same data.
2022-04-26 05:54:24 | INFO | fairseq.tasks.translation | example reference: now, it's no surprise that when you add consecutive fibonacci numbers, you get the next fibonacci number. right?
2022-04-26 05:54:25 | INFO | fairseq.tasks.translation | example hypothesis: but we're not going to do it yet.
2022-04-26 05:54:25 | INFO | fairseq.tasks.translation | example reference: yet we dither, taking no action to deflect the UNKNOWNTOKENINREF id, even though the longer we wait, the more difficult and expensive it becomes. "
2022-04-26 05:54:27 | INFO | fairseq.tasks.translation | example hypothesis: he told me that he had a friend of mine who he met when he was 17.
2022-04-26 05:54:27 | INFO | fairseq.tasks.translation | example reference: he had this amazing series of hairs growing out of a mole on the left side of his face, which i'm told is very good luck.
2022-04-26 05:54:28 | INFO | fairseq.tasks.translation | example hypothesis: this is the first synesthetic cell, and it's the first synesthetic cell, and it's the first synesthetic cell.
2022-04-26 05:54:28 | INFO | fairseq.tasks.translation | example reference: here's the first battery -- a stack of coins, zinc and silver, separated by cardboard soaked in brine.
2022-04-26 05:54:29 | INFO | fairseq.tasks.translation | example hypothesis: and he said that in the united states of the united states, the state of the union, the state of the union, the state of the union, the state of the union, the state of the union.
2022-04-26 05:54:29 | INFO | fairseq.tasks.translation | example reference: durkheim called this level the level of the sacred because he believed that the function of religion was to unite people into a group, into a moral community.
2022-04-26 05:54:31 | INFO | fairseq.tasks.translation | example hypothesis: but when you look at the map of the ocean, it's a map of the ocean, and it's a map of the ocean.
2022-04-26 05:54:31 | INFO | fairseq.tasks.translation | example reference: but the UNKNOWNTOKENINREF match up if i rotate by a sixth of a turn around the point where all the trianUNKNOWNTOKENINREF meet.
2022-04-26 05:54:33 | INFO | fairseq.tasks.translation | example hypothesis: and when you look at these animals, and you look at these animals, and you look at these animals, and you look at these animals, and you look at these animals, and you look at these animals.
2022-04-26 05:54:33 | INFO | fairseq.tasks.translation | example reference: there's little brochures all around outside, and if any of you have anything to do with children and care about their future, i beg that you pick up that brochure.
2022-04-26 05:54:34 | INFO | fairseq.tasks.translation | example hypothesis: and it costs about four dollars to build a car.
2022-04-26 05:54:34 | INFO | fairseq.tasks.translation | example reference: and this is only done in four hours, 50 times faster than the current state of the art, at a cost that will be five to 500 times cheaper than the current options.
2022-04-26 05:54:35 | INFO | fairseq.tasks.translation | example hypothesis: what you can learn from studying UNKNOWNTOKENINHYP, and what you can learn from studying UNKNOWNTOKENINHYP, and what you can learn from studying UNKNOWNTOKENINHYP, what you can learn from studying UNKNOWNTOKENINHYP, what you can learn from studying UNKNOWNTOKENINHYP.
2022-04-26 05:54:35 | INFO | fairseq.tasks.translation | example reference: i'm fascinated with the idea of what happens when you merge UNKNOWNTOKENINREF with technology, and i remember reading about this idea of being able to reprogram UNKNOWNTOKENINREF, in the future, away from disease and aging.
2022-04-26 05:54:37 | INFO | fairseq.tasks.translation | example hypothesis: but the problem is that you have to solve the problem, and you have to solve the problem, and you have to solve the problem.
2022-04-26 05:54:37 | INFO | fairseq.tasks.translation | example reference: but the problem with relying on rules and inUNKNOWNTOKENINREF ves is that they demorUNKNOWNTOKENINREF professional activity, and they demorUNKNOWNTOKENINREF professional activity in two UNKNOWNTOKENINREF.
2022-04-26 05:54:38 | INFO | fairseq.tasks.translation | example hypothesis: i said, "you know, we've been working on this for a long time."
2022-04-26 05:54:38 | INFO | fairseq.tasks.translation | example reference: i belong to an internet discussion forum, an UNKNOWNTOKENINREF internet discussion forum, and i asked them, i said, "since 1960, we've had exactly 204 UNKNOWNTOKENINREF heads of state, since 1960."
2022-04-26 05:54:39 | INFO | fairseq.tasks.translation | example hypothesis: and when i got really excited about this, i thought, well, i really loved it, and i really loved it, and i really loved it, and i really loved it.
2022-04-26 05:54:39 | INFO | fairseq.tasks.translation | example reference: and as these dark clouds were circling me, and i was finding it really, really difficult to think of anything good, i said to myself that i really needed a way to focus on the positive somehow.
2022-04-26 05:54:41 | INFO | fairseq.tasks.translation | example hypothesis: you'd think it would be just like the wind would be blowing blowing blowing blowing blowing blowing blowing blowing blowing blowing blowing blowing blowing blowing blowing blowing blowing blowing blowing blowing blowing blowing blowing blowing blowing blowing blowing blowing blowers
2022-04-26 05:54:41 | INFO | fairseq.tasks.translation | example reference: for example, gUNKNOWNTOKENINREF age discharge, something you would think just simply goes away, but the laws regulating ship discharge of gUNKNOWNTOKENINREF age actually get weaker the further you are from shore.
2022-04-26 05:54:42 | INFO | fairseq.tasks.translation | example hypothesis: he had to do it for himself, and he had to do it for himself.
2022-04-26 05:54:42 | INFO | fairseq.tasks.translation | example reference: see, he owned a UNKNOWNTOKENINREF mium plating company, and they had to move heavy steel parts between tanks of chemicals, and so he needed an industrial robot like this that could basically do the heavy lifting.
2022-04-26 05:54:43 | INFO | fairseq.tasks.translation | example hypothesis: and what they're doing is they're sending signals to the rest of the world, sending signals to the rest of the world.
2022-04-26 05:54:43 | INFO | fairseq.tasks.translation | example reference: and the religious police imposes the supposed UNKNOWNTOKENINREF ic way of life on every citizen, by force -- like women are forced to cover their heads -- wear the hijab, the UNKNOWNTOKENINREF ic head cover.
2022-04-26 05:54:45 | INFO | fairseq.tasks.translation | example hypothesis: most of the world's population are living in poverty, poverty, poverty, poverty.
2022-04-26 05:54:45 | INFO | fairseq.tasks.translation | example reference: come with me to the bottom of the world, antUNKNOWNTOKENINREF tica, the highest, driest, windiest, and yes, coldest region on earth -- more arid than the UNKNOWNTOKENINREF a and, in parts, colder than UNKNOWNTOKENINREF.
2022-04-26 05:54:46 | INFO | fairseq.tasks.translation | example hypothesis: you can see here, he's my father, he's his son, he's his son.
2022-04-26 05:54:46 | INFO | fairseq.tasks.translation | example reference: that's kellar autumn, my former ph.d. student, professor now at lewis and clark, literally giving his firUNKNOWNTOKENINREF born child up for this test.
2022-04-26 05:54:47 | INFO | fairseq.tasks.translation | example hypothesis: it's a great honor to be part of ted's team, and it's a great honor to be part of the team, and it's a great honor to be part of the team.
2022-04-26 05:54:47 | INFO | fairseq.tasks.translation | example reference: however, while it's easier to think of us, the citizens, the police, the army, as the good guys, and them, the narcos, the carteles, as the bad guys, if you think about it, the latter are only providing a service to the former.
2022-04-26 05:54:49 | INFO | fairseq.tasks.translation | example hypothesis: and for those of you who live in the inner city, it was very exciting for those of you who live in the inner city.
2022-04-26 05:54:49 | INFO | fairseq.tasks.translation | example reference: and for the following 25 years, living in italy, living in UNKNOWNTOKENINREF, i doled out a piece of this romance to anybody who'd pay for it -- this sense, this aesthetic feeling, for the experience revolving around a designed object.
2022-04-26 05:54:50 | INFO | fairseq.tasks.translation | example hypothesis: we have a problem in the united states, but we have a problem in the united states, and we have a problem in the united states.
2022-04-26 05:54:50 | INFO | fairseq.tasks.translation | example reference: because we've UNKNOWNTOKENINREF the problem in chubut province, which is like a state in argentina where punta tombo is -- so that's about 1,000 UNKNOWNTOKENINREF of coastline -- but we haven't UNKNOWNTOKENINREF the problem in northern argentina, uruguay and UNKNOWNTOKENINREF.
2022-04-26 05:54:51 | INFO | fairseq.tasks.translation | example hypothesis: it says, "you know what, we're going to do a little bit of a dummies."
2022-04-26 05:54:51 | INFO | fairseq.tasks.translation | example reference: animal fan nellie mckay sings a sparkling UNKNOWNTOKENINREF te to her dear dog. she suggests we all do the same: "just go right to the pound / and find yourself a hound / and make that doggie proud / 'cause that's what it's all about."
2022-04-26 05:54:53 | INFO | fairseq.tasks.translation | example hypothesis: it turns out that there's a huge amount of water coming out of the ocean, and it turns out that the ocean has been absorbed by the ocean for billions of years.
2022-04-26 05:54:53 | INFO | fairseq.tasks.translation | example reference: with streams and rivers drying up because of over-usage, rob harmon has UNKNOWNTOKENINREF mented an ingenious market mechanism to bring back the water. farmers and beer companies find their fates intertwined in the intriguing centurUNKNOWNTOKENINREF old tale of prickly pear creek. & lt; em & gt; & lt; / em & gt;
2022-04-26 05:54:54 | INFO | fairseq.tasks.translation | example hypothesis: and what we find is that most people in the developing world spend most of their lives in places that they don't know.
2022-04-26 05:54:54 | INFO | fairseq.tasks.translation | example reference: and the reality of the society that we're in is there are thousands and thousands of people out there leading lives of quiet, screaming desperation, where they work long, hard hours at jobs they hate to enable them to buy things they don't need to impress people they don't like.
2022-04-26 05:54:55 | INFO | fairseq.tasks.translation | example hypothesis: and i'm going to tell you a little bit about the world that we've created.
2022-04-26 05:54:55 | INFO | fairseq.tasks.translation | example reference: and i organize it. and, well, it's also a bit different because an UNKNOWNTOKENINREF versus, let's say, a dance company finally is a negotiation between one's private world, one's UNKNOWNTOKENINREF tual world, the world of ideas, the world of aspirations, of UNKNOWNTOKENINREF tions, with the relationship of the exterior world and all the limitations, the naysayers.
2022-04-26 05:54:57 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to use these tools to help us solve these kinds of problems, but we're also going to use these tools to help us solve these kinds of problems.
2022-04-26 05:54:57 | INFO | fairseq.tasks.translation | example reference: and i also hope that you share the idea that if engineers and UNKNOWNTOKENINREF can use all these different climatic parameters, it will be possible to create really good and comfortable outdoor conditions, to change our thermal perception that we feel comfortable in an outdoor environment, and we can do that with the best passive design, but also using the energy source of the site in qatar which is the sun.
2022-04-26 05:54:58 | INFO | fairseq.tasks.translation | example hypothesis: now, i know that i've always been fascinated, but i've always been fascinated, and i've always been fascinated, and i've always been fascinated, and i've always been fascinated, and i've always been fascinated.
2022-04-26 05:54:58 | INFO | fairseq.tasks.translation | example reference: i used to say that these people saved me, but what i now know is they did something even more important in that they empowered me to save myself, and crucially, they helped me to understand something which i'd always UNKNOWNTOKENINREF pected: that my voices were a meaningful response to traumatic life events, particularly childhood events, and as such were not my enemies but a source of insight into solvable emotional problems.
2022-04-26 05:54:59 | INFO | fairseq.tasks.translation | example hypothesis: and then we said, "well, you know, it's a great honor to be here at ted."
2022-04-26 05:54:59 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at UNKNOWNTOKENINREF women is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-04-26 05:55:00 | INFO | fairseq.tasks.translation | example hypothesis: we were able to make a map of the universe, and we were able to see that the universe was always proportionate to the size of the universe and the size of the universe.
2022-04-26 05:55:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of UNKNOWNTOKENINREF, and a lot of the design work that we're the most proud of with the aircraft came out of UNKNOWNTOKENINREF the unique problems of operating it on the ground -- everything from a continuouslUNKNOWNTOKENINREF variable transmission and liquiUNKNOWNTOKENINREF based cooling system that allows us to use an aircraft engine in stop-UNKNOWNTOKENINREF go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wUNKNOWNTOKENINREF folding mechanism that we'll see in a moment, to crash safety features.
2022-04-26 05:55:00 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 6.149 | nll_loss 4.693 | ppl 25.87 | bleu 4.06 | wps 2156.2 | wpb 2835.3 | bsz 115.6 | num_updates 3306
2022-04-26 05:55:00 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-04-26 05:55:00 | INFO | train | epoch 003 | loss 6.184 | nll_loss 4.724 | ppl 26.42 | wps 5853.9 | ups 1.63 | wpb 3583.6 | bsz 145.4 | num_updates 3306 | lr 0.00041325 | gnorm 8.685 | train_wall 582 | gb_free 6.1 | wall 2067
2022-04-26 05:55:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2022-04-26 05:55:00 | INFO | fairseq.trainer | begin training epoch 4
2022-04-26 05:55:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-04-26 05:55:50 | INFO | train_inner | epoch 004:     94 / 1102 loss=5.791, nll_loss=4.307, ppl=19.79, wps=2613.4, ups=0.73, wpb=3579.5, bsz=150.6, num_updates=3400, lr=0.000425, gnorm=5.391, train_wall=53, gb_free=6, wall=2117
2022-04-26 05:56:44 | INFO | train_inner | epoch 004:    194 / 1102 loss=5.903, nll_loss=4.419, ppl=21.4, wps=6540.2, ups=1.85, wpb=3536.2, bsz=137.7, num_updates=3500, lr=0.0004375, gnorm=6.246, train_wall=53, gb_free=6.4, wall=2171
2022-04-26 05:57:38 | INFO | train_inner | epoch 004:    294 / 1102 loss=5.939, nll_loss=4.475, ppl=22.24, wps=6754.9, ups=1.85, wpb=3648.2, bsz=131.6, num_updates=3600, lr=0.00045, gnorm=5.282, train_wall=53, gb_free=7.1, wall=2225
2022-04-26 05:58:31 | INFO | train_inner | epoch 004:    394 / 1102 loss=5.993, nll_loss=4.524, ppl=23, wps=6595.1, ups=1.88, wpb=3504.1, bsz=136.6, num_updates=3700, lr=0.0004625, gnorm=7.178, train_wall=52, gb_free=6.7, wall=2278
2022-04-26 05:59:25 | INFO | train_inner | epoch 004:    494 / 1102 loss=5.989, nll_loss=4.527, ppl=23.05, wps=6738.1, ups=1.86, wpb=3619.9, bsz=138.5, num_updates=3800, lr=0.000475, gnorm=5.586, train_wall=53, gb_free=5.8, wall=2332
2022-04-26 06:00:18 | INFO | train_inner | epoch 004:    594 / 1102 loss=6.016, nll_loss=4.561, ppl=23.61, wps=6712.7, ups=1.88, wpb=3576.6, bsz=140.7, num_updates=3900, lr=0.0004875, gnorm=5.59, train_wall=53, gb_free=6.5, wall=2385
2022-04-26 06:01:12 | INFO | train_inner | epoch 004:    694 / 1102 loss=6.061, nll_loss=4.609, ppl=24.4, wps=6700.1, ups=1.85, wpb=3616, bsz=144.3, num_updates=4000, lr=0.0005, gnorm=5.334, train_wall=53, gb_free=6.2, wall=2439
2022-04-26 06:02:06 | INFO | train_inner | epoch 004:    794 / 1102 loss=6.031, nll_loss=4.568, ppl=23.73, wps=6603.9, ups=1.87, wpb=3530.2, bsz=161.6, num_updates=4100, lr=0.000493865, gnorm=6.328, train_wall=53, gb_free=6.2, wall=2493
2022-04-26 06:02:59 | INFO | train_inner | epoch 004:    894 / 1102 loss=6.103, nll_loss=4.653, ppl=25.15, wps=6669.1, ups=1.87, wpb=3567.8, bsz=153.2, num_updates=4200, lr=0.00048795, gnorm=6.626, train_wall=53, gb_free=6.4, wall=2546
2022-04-26 06:03:53 | INFO | train_inner | epoch 004:    994 / 1102 loss=5.993, nll_loss=4.539, ppl=23.24, wps=6782, ups=1.86, wpb=3652, bsz=144.6, num_updates=4300, lr=0.000482243, gnorm=4.918, train_wall=53, gb_free=6.2, wall=2600
2022-04-26 06:04:47 | INFO | train_inner | epoch 004:   1094 / 1102 loss=5.947, nll_loss=4.484, ppl=22.38, wps=6661, ups=1.86, wpb=3587, bsz=161, num_updates=4400, lr=0.000476731, gnorm=5.315, train_wall=53, gb_free=6.4, wall=2654
2022-04-26 06:04:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-04-26 06:04:53 | INFO | fairseq.tasks.translation | example hypothesis: they're not moving around.
2022-04-26 06:04:53 | INFO | fairseq.tasks.translation | example reference: they're just not moving.
2022-04-26 06:04:54 | INFO | fairseq.tasks.translation | example hypothesis: so i said, "what is that?"
2022-04-26 06:04:54 | INFO | fairseq.tasks.translation | example reference: i was like "what?"
2022-04-26 06:04:55 | INFO | fairseq.tasks.translation | example hypothesis: all of this is no longer possible. right?
2022-04-26 06:04:55 | INFO | fairseq.tasks.translation | example reference: is it all worked out? no.
2022-04-26 06:04:57 | INFO | fairseq.tasks.translation | example hypothesis: we need to learn more.
2022-04-26 06:04:57 | INFO | fairseq.tasks.translation | example reference: we need to use less to make more.
2022-04-26 06:04:58 | INFO | fairseq.tasks.translation | example hypothesis: but mahmoud lives.
2022-04-26 06:04:58 | INFO | fairseq.tasks.translation | example reference: but homage to singUNKNOWNTOKENINREF re.
2022-04-26 06:04:59 | INFO | fairseq.tasks.translation | example hypothesis: we call this the UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP of the multiplication.
2022-04-26 06:04:59 | INFO | fairseq.tasks.translation | example reference: we call this UNKNOWNTOKENINREF tational lensing.
2022-04-26 06:05:00 | INFO | fairseq.tasks.translation | example hypothesis: now think of UNKNOWNTOKENINHYP as social UNKNOWNTOKENINHYP.
2022-04-26 06:05:00 | INFO | fairseq.tasks.translation | example reference: well, consider by UNKNOWNTOKENINREF y, the concept of physical health.
2022-04-26 06:05:02 | INFO | fairseq.tasks.translation | example hypothesis: that's really the key to UNKNOWNTOKENINHYP vering the UNKNOWNTOKENINHYP.
2022-04-26 06:05:02 | INFO | fairseq.tasks.translation | example reference: these are the classic conditions that create regret.
2022-04-26 06:05:03 | INFO | fairseq.tasks.translation | example hypothesis: UNKNOWNTOKENINHYP ability, UNKNOWNTOKENINHYP ability, UNKNOWNTOKENINHYP ability.
2022-04-26 06:05:03 | INFO | fairseq.tasks.translation | example reference: valence means good or bad, positive or negative.
2022-04-26 06:05:04 | INFO | fairseq.tasks.translation | example hypothesis: the bad news is that it's cheaper.
2022-04-26 06:05:04 | INFO | fairseq.tasks.translation | example reference: the bad news is they're rocket fuels.
2022-04-26 06:05:06 | INFO | fairseq.tasks.translation | example hypothesis: it can be used as a way of measuring things.
2022-04-26 06:05:06 | INFO | fairseq.tasks.translation | example reference: it can be used for calculating UNKNOWNTOKENINREF equations of all different types.
2022-04-26 06:05:07 | INFO | fairseq.tasks.translation | example hypothesis: we should be thinking about this, and we should be thinking about it. we should be thinking about it.
2022-04-26 06:05:07 | INFO | fairseq.tasks.translation | example reference: we should probably slow down, and that point of action is probably now.
2022-04-26 06:05:09 | INFO | fairseq.tasks.translation | example hypothesis: so we decided to use the UNKNOWNTOKENINHYP of UNKNOWNTOKENINHYP and the UNKNOWNTOKENINHYP of UNKNOWNTOKENINHYP to create products. and we decided to use the UNKNOWNTOKENINHYP of UNKNOWNTOKENINHYP.
2022-04-26 06:05:09 | INFO | fairseq.tasks.translation | example reference: decided to use UNKNOWNTOKENINREF ed content from cement and steel manufacturing.
2022-04-26 06:05:10 | INFO | fairseq.tasks.translation | example hypothesis: the last two years, we've had the extraordinary privilege of UNKNOWNTOKENINHYP vering ancient UNKNOWNTOKENINHYP.
2022-04-26 06:05:10 | INFO | fairseq.tasks.translation | example reference: just in the last two days, we got the new temperature UNKNOWNTOKENINREF ds in UNKNOWNTOKENINREF ary.
2022-04-26 06:05:12 | INFO | fairseq.tasks.translation | example hypothesis: what's really interesting is that this is actually something that has to do with the fact that the UNKNOWNTOKENINHYP al cord has a UNKNOWNTOKENINHYP al cord.
2022-04-26 06:05:12 | INFO | fairseq.tasks.translation | example reference: and to remind you that here is an example in which architecture actually did something.
2022-04-26 06:05:13 | INFO | fairseq.tasks.translation | example hypothesis: this mother never found her loved ones.
2022-04-26 06:05:13 | INFO | fairseq.tasks.translation | example reference: and the grandmother had never let any westerners ever see her.
2022-04-26 06:05:15 | INFO | fairseq.tasks.translation | example hypothesis: that's something we've been learning for a long time, so we don't know what's going on.
2022-04-26 06:05:15 | INFO | fairseq.tasks.translation | example reference: this is something we've actually known for a while, so it's not a real breakthrough.
2022-04-26 06:05:17 | INFO | fairseq.tasks.translation | example hypothesis: it's a social system.
2022-04-26 06:05:17 | INFO | fairseq.tasks.translation | example reference: it's a social awkwardness like you're a stranger in a foreign land.
2022-04-26 06:05:18 | INFO | fairseq.tasks.translation | example hypothesis: learn to read. learn to read. learn to read.
2022-04-26 06:05:18 | INFO | fairseq.tasks.translation | example reference: i had learned to read music by then, or slowly learning to read music.
2022-04-26 06:05:20 | INFO | fairseq.tasks.translation | example hypothesis: and they said, "no, we would like you to go out for lunch. we would like you to go for lunch.
2022-04-26 06:05:20 | INFO | fairseq.tasks.translation | example reference: they said they were going to beat us up if we didn't make some gunpowder for them.
2022-04-26 06:05:21 | INFO | fairseq.tasks.translation | example hypothesis: now, we're using satellite tags from satellite tags, from satellite tags from satellite tags.
2022-04-26 06:05:21 | INFO | fairseq.tasks.translation | example reference: well, we collect data from satellites, from airplanes, from ground UNKNOWNTOKENINREF cles, from people.
2022-04-26 06:05:23 | INFO | fairseq.tasks.translation | example hypothesis: and one of the most incredible things that was going on was this incredible UNKNOWNTOKENINHYP with all of these people.
2022-04-26 06:05:23 | INFO | fairseq.tasks.translation | example reference: and one of the UNKNOWNTOKENINREF things that happened was this act of actually connecting to all these people.
2022-04-26 06:05:24 | INFO | fairseq.tasks.translation | example hypothesis: i'd like to share with you an idea that i'd like to share with you.
2022-04-26 06:05:24 | INFO | fairseq.tasks.translation | example reference: i want to share one story about an innovation called drip irriUNKNOWNTOKENINREF.
2022-04-26 06:05:26 | INFO | fairseq.tasks.translation | example hypothesis: this man was his mother, and this man was his grandmother, and this man was his grandmother.
2022-04-26 06:05:26 | INFO | fairseq.tasks.translation | example reference: the man, his name was mahmoud, and the child, whose name was rafi, left.
2022-04-26 06:05:28 | INFO | fairseq.tasks.translation | example hypothesis: and here's what it looks like to me.
2022-04-26 06:05:28 | INFO | fairseq.tasks.translation | example reference: and that allows me to check my timer discretely, here, without bending my elbow.
2022-04-26 06:05:29 | INFO | fairseq.tasks.translation | example hypothesis: our home was closed for a while.
2022-04-26 06:05:29 | INFO | fairseq.tasks.translation | example reference: she arrived at our reserve from a reserve east of us on her UNKNOWNTOKENINREF atory route.
2022-04-26 06:05:31 | INFO | fairseq.tasks.translation | example hypothesis: and when we think about the future, i think we're going to be able to do the same thing for the rest of our lives, for the rest of our lives.
2022-04-26 06:05:31 | INFO | fairseq.tasks.translation | example reference: if we can make it through the next 150 years, i think that your great great grandchildren will forget all about malthus.
2022-04-26 06:05:33 | INFO | fairseq.tasks.translation | example hypothesis: and this is a process of biofabrication and biofabrication and biofabrication and biofabrication and biofabrication and biofabrication and biofabrication.
2022-04-26 06:05:33 | INFO | fairseq.tasks.translation | example reference: those are then selected by the UNKNOWNTOKENINREF m, reproduced with mutation and reUNKNOWNTOKENINREF ations to introduce sex as well.
2022-04-26 06:05:35 | INFO | fairseq.tasks.translation | example hypothesis: it's not too bad, but it's going to make a lot of money.
2022-04-26 06:05:35 | INFO | fairseq.tasks.translation | example reference: now, it just shouldn't take these sorts of efforts to find out where the money in deals like this went.
2022-04-26 06:05:36 | INFO | fairseq.tasks.translation | example hypothesis: and if you don't do that, you're not going to do that.
2022-04-26 06:05:36 | INFO | fairseq.tasks.translation | example reference: when people don't take their pills, when people don't follow doctors' orders -- these are behavior problems.
2022-04-26 06:05:38 | INFO | fairseq.tasks.translation | example hypothesis: that's how most of the rest of the world, when you're living on a planet like UNKNOWNTOKENINHYP, UNKNOWNTOKENINHYP, UNKNOWNTOKENINHYP, UNKNOWNTOKENINHYP, UNKNOWNTOKENINHYP, UNKNOWNTOKENINHYP, UNKNOWNTOKENINHYP, UNKNOWNTOKENINHYP, UNKNOWNTOKENINHYP, UNKNOWNTOKENINHYP, whatever.
2022-04-26 06:05:38 | INFO | fairseq.tasks.translation | example reference: so it's pretty sad to find that UNKNOWNTOKENINREF es, like so many other UNKNOWNTOKENINREF around the world, are losing their habitats.
2022-04-26 06:05:40 | INFO | fairseq.tasks.translation | example hypothesis: and we've been doing this for a couple of years, and this is a moment in time for us to think that we're going to make a difference in the way we think and act.
2022-04-26 06:05:40 | INFO | fairseq.tasks.translation | example reference: we discovered bluegrass a few years ago, and we fell in love with it. we hope you guys will too.
2022-04-26 06:05:42 | INFO | fairseq.tasks.translation | example hypothesis: so i thought, what can we do?
2022-04-26 06:05:42 | INFO | fairseq.tasks.translation | example reference: so i was trying to, you know, take the engineer's version: can we build a mechanical system in inorganic materials that will do the same thing?
2022-04-26 06:05:43 | INFO | fairseq.tasks.translation | example hypothesis: we've talked about UNKNOWNTOKENINHYP with the national UNKNOWNTOKENINHYP of science, with the national UNKNOWNTOKENINHYP of science, with the national UNKNOWNTOKENINHYP of science, with the national UNKNOWNTOKENINHYP of science, with the national UNKNOWNTOKENINHYP of science, with the national UNKNOWNTOKENINHYP of science.
2022-04-26 06:05:43 | INFO | fairseq.tasks.translation | example reference: we consult to the media about canopy questions; we have a canopy newsletter; we have an email listserv.
2022-04-26 06:05:45 | INFO | fairseq.tasks.translation | example hypothesis: today, i want to share with you my personal adventure with you.
2022-04-26 06:05:45 | INFO | fairseq.tasks.translation | example reference: what my purpose of the talk today really is, is to sort of indelibly scar your minds with these charismatic and majestic UNKNOWNTOKENINREF.
2022-04-26 06:05:47 | INFO | fairseq.tasks.translation | example hypothesis: so it turns out that if you think about it for a long time, it's not going to be that easy, and it's not going to be that easy, it's not going to be that easy.
2022-04-26 06:05:47 | INFO | fairseq.tasks.translation | example reference: now, it's no surprise that when you add consecutive fibonacci numbers, you get the next fibonacci number. right?
2022-04-26 06:05:49 | INFO | fairseq.tasks.translation | example hypothesis: but we're still going to do more of it, and we're still going to do more of it, and we're still going to do more of it, and we're going to do more of it.
2022-04-26 06:05:49 | INFO | fairseq.tasks.translation | example reference: yet we dither, taking no action to deflect the UNKNOWNTOKENINREF id, even though the longer we wait, the more difficult and expensive it becomes. "
2022-04-26 06:05:51 | INFO | fairseq.tasks.translation | example hypothesis: and he was very interested in the idea that he was going to make a very big announcement about the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP.
2022-04-26 06:05:51 | INFO | fairseq.tasks.translation | example reference: he had this amazing series of hairs growing out of a mole on the left side of his face, which i'm told is very good luck.
2022-04-26 06:05:53 | INFO | fairseq.tasks.translation | example hypothesis: this is the first UNKNOWNTOKENINHYP e, and this is the first UNKNOWNTOKENINHYP e, and this is the first UNKNOWNTOKENINHYP e, and this is the first UNKNOWNTOKENINHYP e, and this is the first UNKNOWNTOKENINHYP e, and this is the first UNKNOWNTOKENINHYP e, and this is a UNKNOWNTOKENINHYP e.
2022-04-26 06:05:53 | INFO | fairseq.tasks.translation | example reference: here's the first battery -- a stack of coins, zinc and silver, separated by cardboard soaked in brine.
2022-04-26 06:05:55 | INFO | fairseq.tasks.translation | example hypothesis: and this is a group of people in UNKNOWNTOKENINHYP who decided that this was important, because they thought that this was the kind of language that was supposed to be used by the UNKNOWNTOKENINHYP community.
2022-04-26 06:05:55 | INFO | fairseq.tasks.translation | example reference: durkheim called this level the level of the sacred because he believed that the function of religion was to unite people into a group, into a moral community.
2022-04-26 06:05:57 | INFO | fairseq.tasks.translation | example hypothesis: but i'm going to tell you a little bit about the origin of species, and the origin of species, and the origin of species.
2022-04-26 06:05:57 | INFO | fairseq.tasks.translation | example reference: but the UNKNOWNTOKENINREF match up if i rotate by a sixth of a turn around the point where all the trianUNKNOWNTOKENINREF meet.
2022-04-26 06:05:59 | INFO | fairseq.tasks.translation | example hypothesis: and if you're sitting in front of a computer, and you're sitting in front of a computer, and you're sitting in front of a computer, and you're sitting in front of a computer, and you're sitting in front of a computer, and you're sitting in front of a computer
2022-04-26 06:05:59 | INFO | fairseq.tasks.translation | example reference: there's little brochures all around outside, and if any of you have anything to do with children and care about their future, i beg that you pick up that brochure.
2022-04-26 06:06:02 | INFO | fairseq.tasks.translation | example hypothesis: and it's about 1.4 billion dollars a year. it's about 1.4 billion dollars a year.
2022-04-26 06:06:02 | INFO | fairseq.tasks.translation | example reference: and this is only done in four hours, 50 times faster than the current state of the art, at a cost that will be five to 500 times cheaper than the current options.
2022-04-26 06:06:04 | INFO | fairseq.tasks.translation | example hypothesis: what i'm going to do is try to figure out what's going on in the brain, and i'll try to figure out what's going on in the brain, and i'll try to figure out what's going on.
2022-04-26 06:06:04 | INFO | fairseq.tasks.translation | example reference: i'm fascinated with the idea of what happens when you merge UNKNOWNTOKENINREF with technology, and i remember reading about this idea of being able to reprogram UNKNOWNTOKENINREF, in the future, away from disease and aging.
2022-04-26 06:06:06 | INFO | fairseq.tasks.translation | example hypothesis: but the problem is that they do it in a way that creates meaning and creates meaning and creates meaning in their lives.
2022-04-26 06:06:06 | INFO | fairseq.tasks.translation | example reference: but the problem with relying on rules and inUNKNOWNTOKENINREF ves is that they demorUNKNOWNTOKENINREF professional activity, and they demorUNKNOWNTOKENINREF professional activity in two UNKNOWNTOKENINREF.
2022-04-26 06:06:08 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "well, you know, i'm going to do a research center for the national library of medicine at the national library of medicine at the national library of medicine, and i'm going to do a research center for the national library of medicine at the national library of medicine at the national library of medicine."
2022-04-26 06:06:08 | INFO | fairseq.tasks.translation | example reference: i belong to an internet discussion forum, an UNKNOWNTOKENINREF internet discussion forum, and i asked them, i said, "since 1960, we've had exactly 204 UNKNOWNTOKENINREF heads of state, since 1960."
2022-04-26 06:06:10 | INFO | fairseq.tasks.translation | example hypothesis: and i thought, you know, there's something really interesting going on, and i'm going to try and figure out a way to do that, and i'm going to try and figure out a way to do that.
2022-04-26 06:06:10 | INFO | fairseq.tasks.translation | example reference: and as these dark clouds were circling me, and i was finding it really, really difficult to think of anything good, i said to myself that i really needed a way to focus on the positive somehow.
2022-04-26 06:06:12 | INFO | fairseq.tasks.translation | example hypothesis: but it turns out, as you can imagine, it's going to depend on the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP
2022-04-26 06:06:12 | INFO | fairseq.tasks.translation | example reference: for example, gUNKNOWNTOKENINREF age discharge, something you would think just simply goes away, but the laws regulating ship discharge of gUNKNOWNTOKENINREF age actually get weaker the further you are from shore.
2022-04-26 06:06:15 | INFO | fairseq.tasks.translation | example hypothesis: so you had to use a UNKNOWNTOKENINHYP e to do this, and you had to use a UNKNOWNTOKENINHYP e to do this. and you had to use a UNKNOWNTOKENINHYP e to do this. and you had to use a UNKNOWNTOKENINHYP e to do this. and you had to use a UNKNOWNTOKENINHYP e to do this. and you had to use a UNKNOWNTOKENINHYP e to do this.
2022-04-26 06:06:15 | INFO | fairseq.tasks.translation | example reference: see, he owned a UNKNOWNTOKENINREF mium plating company, and they had to move heavy steel parts between tanks of chemicals, and so he needed an industrial robot like this that could basically do the heavy lifting.
2022-04-26 06:06:17 | INFO | fairseq.tasks.translation | example hypothesis: and they do the same thing with the UNKNOWNTOKENINHYP horus, the UNKNOWNTOKENINHYP horus, the UNKNOWNTOKENINHYP horus.
2022-04-26 06:06:17 | INFO | fairseq.tasks.translation | example reference: and the religious police imposes the supposed UNKNOWNTOKENINREF ic way of life on every citizen, by force -- like women are forced to cover their heads -- wear the hijab, the UNKNOWNTOKENINREF ic head cover.
2022-04-26 06:06:19 | INFO | fairseq.tasks.translation | example hypothesis: most of the world's most vulnerable, most vulnerable, most vulnerable, most vulnerable, most vulnerable, most vulnerable, most vulnerable, most vulnerable, most vulnerable, most vulnerable, most vulnerable, most vulnerable.
2022-04-26 06:06:19 | INFO | fairseq.tasks.translation | example reference: come with me to the bottom of the world, antUNKNOWNTOKENINREF tica, the highest, driest, windiest, and yes, coldest region on earth -- more arid than the UNKNOWNTOKENINREF a and, in parts, colder than UNKNOWNTOKENINREF.
2022-04-26 06:06:21 | INFO | fairseq.tasks.translation | example hypothesis: now, here you can see, this is a UNKNOWNTOKENINHYP -UNKNOWNTOKENINHYP olUNKNOWNTOKENINHYP fashioned UNKNOWNTOKENINHYP, and this is the UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP olUNKNOWNTOKENINHYP fashioned UNKNOWNTOKENINHYP, and this is the UNKNOWNTOKENINHYP -UNKNOWNTOKENINHYP olUNKNOWNTOKENINHYP fashioned UNKNOWNTOKENINHYP, and this is the UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP olUNKNOWNTOKENINHYP fashioned UNKNOWNTOKENINHYP.
2022-04-26 06:06:21 | INFO | fairseq.tasks.translation | example reference: that's kellar autumn, my former ph.d. student, professor now at lewis and clark, literally giving his firUNKNOWNTOKENINREF born child up for this test.
2022-04-26 06:06:23 | INFO | fairseq.tasks.translation | example hypothesis: and one of the things that really makes it interesting is that it's the only way to do it, and it's the only way to do it, and it's the only way to do it, and it's the only way to do it, and it's the only way to do it.
2022-04-26 06:06:23 | INFO | fairseq.tasks.translation | example reference: however, while it's easier to think of us, the citizens, the police, the army, as the good guys, and them, the narcos, the carteles, as the bad guys, if you think about it, the latter are only providing a service to the former.
2022-04-26 06:06:26 | INFO | fairseq.tasks.translation | example hypothesis: and i thought, you know, this is the kind of thing that i love to do in the UNKNOWNTOKENINHYP, because i love to live in the UNKNOWNTOKENINHYP, and i love to live in the UNKNOWNTOKENINHYP, and i love to live in the UNKNOWNTOKENINHYP, and i love to live in the UNKNOWNTOKENINHYP, and i love to live in the UNKNOWNTOKENINHYP, and i love to live in the UNKNOWNTOKENINHYP.
2022-04-26 06:06:26 | INFO | fairseq.tasks.translation | example reference: and for the following 25 years, living in italy, living in UNKNOWNTOKENINREF, i doled out a piece of this romance to anybody who'd pay for it -- this sense, this aesthetic feeling, for the experience revolving around a designed object.
2022-04-26 06:06:28 | INFO | fairseq.tasks.translation | example hypothesis: and we've been working on this problem for a while, but it's because we're in the middle of the UNKNOWNTOKENINHYP f of UNKNOWNTOKENINHYP, and we're in the middle of the UNKNOWNTOKENINHYP f of UNKNOWNTOKENINHYP, and we're in the middle of the UNKNOWNTOKENINHYP f of UNKNOWNTOKENINHYP, and we're in the middle of the UNKNOWNTOKENINHYP f of UNKNOWNTOKENINHYP, and we're in the middle of the UNKNOWNTOKENINHYP f of UNKNOWNTOKENINHYP, and we're in the middle of the
2022-04-26 06:06:28 | INFO | fairseq.tasks.translation | example reference: because we've UNKNOWNTOKENINREF the problem in chubut province, which is like a state in argentina where punta tombo is -- so that's about 1,000 UNKNOWNTOKENINREF of coastline -- but we haven't UNKNOWNTOKENINREF the problem in northern argentina, uruguay and UNKNOWNTOKENINREF.
2022-04-26 06:06:31 | INFO | fairseq.tasks.translation | example hypothesis: and they said, "well, you know, we're going to do a little dance, and you're going to do a dance, and you're going to do a dance, and you're going to do a dance, and you're going to do a dance, and you're going to do a dance, and you're going to do a dance, and you're going to do a dance, and you're going to do a dance.
2022-04-26 06:06:31 | INFO | fairseq.tasks.translation | example reference: animal fan nellie mckay sings a sparkling UNKNOWNTOKENINREF te to her dear dog. she suggests we all do the same: "just go right to the pound / and find yourself a hound / and make that doggie proud / 'cause that's what it's all about."
2022-04-26 06:06:33 | INFO | fairseq.tasks.translation | example hypothesis: and it turns out that the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP
2022-04-26 06:06:33 | INFO | fairseq.tasks.translation | example reference: with streams and rivers drying up because of over-usage, rob harmon has UNKNOWNTOKENINREF mented an ingenious market mechanism to bring back the water. farmers and beer companies find their fates intertwined in the intriguing centurUNKNOWNTOKENINREF old tale of prickly pear creek. & lt; em & gt; & lt; / em & gt;
2022-04-26 06:06:36 | INFO | fairseq.tasks.translation | example hypothesis: and there's no reason to believe that we can do that, and we can do that in the UNKNOWNTOKENINHYP, in the UNKNOWNTOKENINHYP, in the UNKNOWNTOKENINHYP, in the UNKNOWNTOKENINHYP, in the UNKNOWNTOKENINHYP, in the UNKNOWNTOKENINHYP, in the UNKNOWNTOKENINHYP, in the UNKNOWNTOKENINHYP, in the UNKNOWNTOKENINHYP, in the UNKNOWNTOKENINHYP, in the UNKNOWNTOKENINHYP, in the UNKNOWNTOKENINHYP, in the UNKNOWNTOKENINHYP, in the UNKNOWNTOKENINHYP, in the UNKNOWNTOKENINHYP, in the UNKNOWNTOKENINHYP, in the UNKNOWNTOKENINHYP, in the UNKNOWNTOKENINHYP, in the UNKNOWNTOKENINHYP, in the UNKNOWNTOKENINHYP, in the UNKNOWNTOKENINHYP, and
2022-04-26 06:06:36 | INFO | fairseq.tasks.translation | example reference: and the reality of the society that we're in is there are thousands and thousands of people out there leading lives of quiet, screaming desperation, where they work long, hard hours at jobs they hate to enable them to buy things they don't need to impress people they don't like.
2022-04-26 06:06:39 | INFO | fairseq.tasks.translation | example hypothesis: and i'm going to tell you a little bit about this, and i'm going to tell you a little bit about this, and i'm going to tell you a little bit about this, and i'm going to tell you a little bit about this, and i'm going to tell you a little bit about this, and i'm going to tell you about this.
2022-04-26 06:06:39 | INFO | fairseq.tasks.translation | example reference: and i organize it. and, well, it's also a bit different because an UNKNOWNTOKENINREF versus, let's say, a dance company finally is a negotiation between one's private world, one's UNKNOWNTOKENINREF tual world, the world of ideas, the world of aspirations, of UNKNOWNTOKENINREF tions, with the relationship of the exterior world and all the limitations, the naysayers.
2022-04-26 06:06:41 | INFO | fairseq.tasks.translation | example hypothesis: and it's very important that we do all of these things, and we do all of these things, and we do all of these things, and we do all of these things, and we do all of these things, and we do all of these things, and we do all of these things, and we do all of these things, and we do all of these things, and we do all of these things, and we do all of these things, and we do all of these things.
2022-04-26 06:06:41 | INFO | fairseq.tasks.translation | example reference: and i also hope that you share the idea that if engineers and UNKNOWNTOKENINREF can use all these different climatic parameters, it will be possible to create really good and comfortable outdoor conditions, to change our thermal perception that we feel comfortable in an outdoor environment, and we can do that with the best passive design, but also using the energy source of the site in qatar which is the sun.
2022-04-26 06:06:44 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "well, you know, i've always been fascinated with UNKNOWNTOKENINHYP, but i've always been fascinated with UNKNOWNTOKENINHYP, and i've always been fascinated with UNKNOWNTOKENINHYP, and i've always been fascinated with UNKNOWNTOKENINHYP, and i've always been fascinated with UNKNOWNTOKENINHYP, and i've always been fascinated with UNKNOWNTOKENINHYP, and i've always been fascinated with UNKNOWNTOKENINHYP, and i've always been interested in UNKNOWNTOKENINHYP, and i've always been interested in UNKNOWNTOKENINHYP, and i've always been interested in UNKNOWNTOKENINHYP, and i've always been interested in UNKNOWNTOKENINHYP, and i've always been interested in UNKNOWNTOKENINHYP, and i've always been interested in UNKNOWNTOKENINHYP, and i've always been interested in UNKNOWNTOKENINHYP.
2022-04-26 06:06:44 | INFO | fairseq.tasks.translation | example reference: i used to say that these people saved me, but what i now know is they did something even more important in that they empowered me to save myself, and crucially, they helped me to understand something which i'd always UNKNOWNTOKENINREF pected: that my voices were a meaningful response to traumatic life events, particularly childhood events, and as such were not my enemies but a source of insight into solvable emotional problems.
2022-04-26 06:06:47 | INFO | fairseq.tasks.translation | example hypothesis: and one of the other things that we did was we went to the library of congress, and we said, "well, you know, you know, you're going to go to the library of congress, and you're going to go to the library of congress, and you're going to go to the library of congress, and you're going to go to the library of congress, and you're going to go to the library of congress, and you're going to go to the library of congress."
2022-04-26 06:06:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at UNKNOWNTOKENINREF women is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-04-26 06:06:48 | INFO | fairseq.tasks.translation | example hypothesis: and we've been working on this for a long time, and we've been working on this for a long time, and we've been working on this for a long time, and we've been working on this for a long time, and we've been working on this for a long time, and we've been working on this for a long time, and we've been working on this for a long time, and we've been working on this for a long time, and we've been working on this for a long time, and we've been working on this for a long time, and we've been working on this for a long time, and we've been building on this for a long time, and we've been building on this for a long time, and we've been building on this for a long time, and we've been building on this for a long time, and we've been building on this for a long time, and we've been building on this for a long time, and we've been building on this for a very
2022-04-26 06:06:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of UNKNOWNTOKENINREF, and a lot of the design work that we're the most proud of with the aircraft came out of UNKNOWNTOKENINREF the unique problems of operating it on the ground -- everything from a continuouslUNKNOWNTOKENINREF variable transmission and liquiUNKNOWNTOKENINREF based cooling system that allows us to use an aircraft engine in stop-UNKNOWNTOKENINREF go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wUNKNOWNTOKENINREF folding mechanism that we'll see in a moment, to crash safety features.
2022-04-26 06:06:48 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 6.056 | nll_loss 4.579 | ppl 23.9 | bleu 4 | wps 1522.1 | wpb 2835.3 | bsz 115.6 | num_updates 4408
2022-04-26 06:06:48 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-04-26 06:06:48 | INFO | train | epoch 004 | loss 5.978 | nll_loss 4.515 | ppl 22.86 | wps 5571.2 | ups 1.55 | wpb 3583.6 | bsz 145.4 | num_updates 4408 | lr 0.000476298 | gnorm 5.785 | train_wall 583 | gb_free 6 | wall 2775
2022-04-26 06:06:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2022-04-26 06:06:48 | INFO | fairseq.trainer | begin training epoch 5
2022-04-26 06:06:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-04-26 06:07:39 | INFO | train_inner | epoch 005:     92 / 1102 loss=5.73, nll_loss=4.227, ppl=18.73, wps=2090.5, ups=0.58, wpb=3591.5, bsz=152.3, num_updates=4500, lr=0.000471405, gnorm=5.987, train_wall=54, gb_free=6.3, wall=2826
2022-04-26 06:08:34 | INFO | train_inner | epoch 005:    192 / 1102 loss=5.548, nll_loss=4.032, ppl=16.36, wps=6615.4, ups=1.83, wpb=3617.3, bsz=152.7, num_updates=4600, lr=0.000466252, gnorm=3.907, train_wall=54, gb_free=6.3, wall=2881
2022-04-26 06:09:28 | INFO | train_inner | epoch 005:    292 / 1102 loss=5.669, nll_loss=4.165, ppl=17.94, wps=6669.2, ups=1.85, wpb=3603.3, bsz=143.8, num_updates=4700, lr=0.000461266, gnorm=4.305, train_wall=53, gb_free=6.4, wall=2935
2022-04-26 06:10:21 | INFO | train_inner | epoch 005:    392 / 1102 loss=5.65, nll_loss=4.147, ppl=17.71, wps=6590.5, ups=1.86, wpb=3542.6, bsz=140.1, num_updates=4800, lr=0.000456435, gnorm=4.186, train_wall=53, gb_free=6.8, wall=2988
2022-04-26 06:11:15 | INFO | train_inner | epoch 005:    492 / 1102 loss=5.739, nll_loss=4.247, ppl=18.99, wps=6582.2, ups=1.87, wpb=3517.5, bsz=129.8, num_updates=4900, lr=0.000451754, gnorm=4.022, train_wall=53, gb_free=6.5, wall=3042
2022-04-26 06:12:08 | INFO | train_inner | epoch 005:    592 / 1102 loss=5.741, nll_loss=4.25, ppl=19.03, wps=6563.7, ups=1.86, wpb=3520, bsz=133.9, num_updates=5000, lr=0.000447214, gnorm=4.118, train_wall=53, gb_free=6.8, wall=3095
2022-04-26 06:13:03 | INFO | train_inner | epoch 005:    692 / 1102 loss=5.583, nll_loss=4.073, ppl=16.83, wps=6760.3, ups=1.84, wpb=3679.1, bsz=162.5, num_updates=5100, lr=0.000442807, gnorm=3.862, train_wall=54, gb_free=6.3, wall=3150
2022-04-26 06:13:57 | INFO | train_inner | epoch 005:    792 / 1102 loss=5.684, nll_loss=4.187, ppl=18.21, wps=6603.8, ups=1.85, wpb=3578.7, bsz=138.1, num_updates=5200, lr=0.000438529, gnorm=3.961, train_wall=53, gb_free=6.7, wall=3204
2022-04-26 06:14:51 | INFO | train_inner | epoch 005:    892 / 1102 loss=5.696, nll_loss=4.196, ppl=18.33, wps=6563.5, ups=1.85, wpb=3546.5, bsz=156.7, num_updates=5300, lr=0.000434372, gnorm=5.02, train_wall=53, gb_free=6.5, wall=3258
2022-04-26 06:15:45 | INFO | train_inner | epoch 005:    992 / 1102 loss=5.66, nll_loss=4.163, ppl=17.91, wps=6668.3, ups=1.86, wpb=3579.5, bsz=139.2, num_updates=5400, lr=0.000430331, gnorm=3.442, train_wall=53, gb_free=6.2, wall=3312
2022-04-26 06:16:39 | INFO | train_inner | epoch 005:   1092 / 1102 loss=5.64, nll_loss=4.14, ppl=17.63, wps=6698.5, ups=1.84, wpb=3634.6, bsz=148.2, num_updates=5500, lr=0.000426401, gnorm=3.61, train_wall=53, gb_free=6.1, wall=3366
2022-04-26 06:16:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-04-26 06:16:46 | INFO | fairseq.tasks.translation | example hypothesis: they don't move.
2022-04-26 06:16:46 | INFO | fairseq.tasks.translation | example reference: they're just not moving.
2022-04-26 06:16:47 | INFO | fairseq.tasks.translation | example hypothesis: so i said, "what?"
2022-04-26 06:16:47 | INFO | fairseq.tasks.translation | example reference: i was like "what?"
2022-04-26 06:16:48 | INFO | fairseq.tasks.translation | example hypothesis: isn't that all?
2022-04-26 06:16:48 | INFO | fairseq.tasks.translation | example reference: is it all worked out? no.
2022-04-26 06:16:49 | INFO | fairseq.tasks.translation | example hypothesis: we need to do more.
2022-04-26 06:16:49 | INFO | fairseq.tasks.translation | example reference: we need to use less to make more.
2022-04-26 06:16:50 | INFO | fairseq.tasks.translation | example hypothesis: but barry schwartz: singing: singing.
2022-04-26 06:16:50 | INFO | fairseq.tasks.translation | example reference: but homage to singUNKNOWNTOKENINREF re.
2022-04-26 06:16:51 | INFO | fairseq.tasks.translation | example hypothesis: we call it the UNKNOWNTOKENINHYP UNKNOWNTOKENINHYP.
2022-04-26 06:16:51 | INFO | fairseq.tasks.translation | example reference: we call this UNKNOWNTOKENINREF tational lensing.
2022-04-26 06:16:53 | INFO | fairseq.tasks.translation | example hypothesis: now think about it.
2022-04-26 06:16:53 | INFO | fairseq.tasks.translation | example reference: well, consider by UNKNOWNTOKENINREF y, the concept of physical health.
2022-04-26 06:16:54 | INFO | fairseq.tasks.translation | example hypothesis: that's the only way to treat disease.
2022-04-26 06:16:54 | INFO | fairseq.tasks.translation | example reference: these are the classic conditions that create regret.
2022-04-26 06:16:56 | INFO | fairseq.tasks.translation | example hypothesis: positive, positive, or negative.
2022-04-26 06:16:56 | INFO | fairseq.tasks.translation | example reference: valence means good or bad, positive or negative.
2022-04-26 06:16:57 | INFO | fairseq.tasks.translation | example hypothesis: the bad news is that it's not going to be bad.
2022-04-26 06:16:57 | INFO | fairseq.tasks.translation | example reference: the bad news is they're rocket fuels.
2022-04-26 06:16:59 | INFO | fairseq.tasks.translation | example hypothesis: it can be used anywhere.
2022-04-26 06:16:59 | INFO | fairseq.tasks.translation | example reference: it can be used for calculating UNKNOWNTOKENINREF equations of all different types.
2022-04-26 06:17:00 | INFO | fairseq.tasks.translation | example hypothesis: we're probably going to be able to do that, and we probably should.
2022-04-26 06:17:00 | INFO | fairseq.tasks.translation | example reference: we should probably slow down, and that point of action is probably now.
2022-04-26 06:17:02 | INFO | fairseq.tasks.translation | example hypothesis: we decided to use UNKNOWNTOKENINHYP tics and UNKNOWNTOKENINHYP tics and UNKNOWNTOKENINHYP tics and UNKNOWNTOKENINHYP tics and UNKNOWNTOKENINHYP tics.
2022-04-26 06:17:02 | INFO | fairseq.tasks.translation | example reference: decided to use UNKNOWNTOKENINREF ed content from cement and steel manufacturing.
2022-04-26 06:17:03 | INFO | fairseq.tasks.translation | example hypothesis: in the new UNKNOWNTOKENINHYP times, we've only heard two new UNKNOWNTOKENINHYP ctions.
2022-04-26 06:17:03 | INFO | fairseq.tasks.translation | example reference: just in the last two days, we got the new temperature UNKNOWNTOKENINREF ds in UNKNOWNTOKENINREF ary.
2022-04-26 06:17:05 | INFO | fairseq.tasks.translation | example hypothesis: so, for example, this is something that has happened to me.
2022-04-26 06:17:05 | INFO | fairseq.tasks.translation | example reference: and to remind you that here is an example in which architecture actually did something.
2022-04-26 06:17:07 | INFO | fairseq.tasks.translation | example hypothesis: none of these stories had ever happened in their lives.
2022-04-26 06:17:07 | INFO | fairseq.tasks.translation | example reference: and the grandmother had never let any westerners ever see her.
2022-04-26 06:17:08 | INFO | fairseq.tasks.translation | example hypothesis: so this is something that we've known for a long time.
2022-04-26 06:17:08 | INFO | fairseq.tasks.translation | example reference: this is something we've actually known for a while, so it's not a real breakthrough.
2022-04-26 06:17:10 | INFO | fairseq.tasks.translation | example hypothesis: it's a social network, if you're not familiar with it.
2022-04-26 06:17:10 | INFO | fairseq.tasks.translation | example reference: it's a social awkwardness like you're a stranger in a foreign land.
2022-04-26 06:17:11 | INFO | fairseq.tasks.translation | example hypothesis: i had to learn to read, learn to read, learn to speak.
2022-04-26 06:17:11 | INFO | fairseq.tasks.translation | example reference: i had learned to read music by then, or slowly learning to read music.
2022-04-26 06:17:13 | INFO | fairseq.tasks.translation | example hypothesis: they said, "no, no, we wouldn't give her a break.
2022-04-26 06:17:13 | INFO | fairseq.tasks.translation | example reference: they said they were going to beat us up if we didn't make some gunpowder for them.
2022-04-26 06:17:15 | INFO | fairseq.tasks.translation | example hypothesis: well, we're talking about satellite tags, satellite tags, satellite tags.
2022-04-26 06:17:15 | INFO | fairseq.tasks.translation | example reference: well, we collect data from satellites, from airplanes, from ground UNKNOWNTOKENINREF cles, from people.
2022-04-26 06:17:17 | INFO | fairseq.tasks.translation | example hypothesis: and one of the most amazing things that was going on with this group was this guy.
2022-04-26 06:17:17 | INFO | fairseq.tasks.translation | example reference: and one of the UNKNOWNTOKENINREF things that happened was this act of actually connecting to all these people.
2022-04-26 06:17:18 | INFO | fairseq.tasks.translation | example hypothesis: i'm going to tell you a story about one of the most interesting projects i'd like to share with you.
2022-04-26 06:17:18 | INFO | fairseq.tasks.translation | example reference: i want to share one story about an innovation called drip irriUNKNOWNTOKENINREF.
2022-04-26 06:17:20 | INFO | fairseq.tasks.translation | example hypothesis: his name was joshua bell, and his name was joshua bell, and his name was joshua bell.
2022-04-26 06:17:20 | INFO | fairseq.tasks.translation | example reference: the man, his name was mahmoud, and the child, whose name was rafi, left.
2022-04-26 06:17:22 | INFO | fairseq.tasks.translation | example hypothesis: and there's no way to treat the patient without cutting off circulation.
2022-04-26 06:17:22 | INFO | fairseq.tasks.translation | example reference: and that allows me to check my timer discretely, here, without bending my elbow.
2022-04-26 06:17:24 | INFO | fairseq.tasks.translation | example hypothesis: on our reserve, our reserve, our reserve, our reserve, our reserve, our reserve, our reserve.
2022-04-26 06:17:24 | INFO | fairseq.tasks.translation | example reference: she arrived at our reserve from a reserve east of us on her UNKNOWNTOKENINREF atory route.
2022-04-26 06:17:26 | INFO | fairseq.tasks.translation | example hypothesis: if i go to the next level, if i go to the next level, if i go to the next level, if i go to the next level, i'll be completely displaced.
2022-04-26 06:17:26 | INFO | fairseq.tasks.translation | example reference: if we can make it through the next 150 years, i think that your great great grandchildren will forget all about malthus.
2022-04-26 06:17:27 | INFO | fairseq.tasks.translation | example hypothesis: so this idea of how to develop some of these UNKNOWNTOKENINHYP ms, and how to develop some of these UNKNOWNTOKENINHYP ms, and how to develop some of these UNKNOWNTOKENINHYP ms, is based on the idea of how these UNKNOWNTOKENINHYP ms
2022-04-26 06:17:27 | INFO | fairseq.tasks.translation | example reference: those are then selected by the UNKNOWNTOKENINREF m, reproduced with mutation and reUNKNOWNTOKENINREF ations to introduce sex as well.
2022-04-26 06:17:29 | INFO | fairseq.tasks.translation | example hypothesis: wouldn't it be great to have a lot of money, but it wouldn't be great to have a lot of resources.
2022-04-26 06:17:29 | INFO | fairseq.tasks.translation | example reference: now, it just shouldn't take these sorts of efforts to find out where the money in deals like this went.
2022-04-26 06:17:31 | INFO | fairseq.tasks.translation | example hypothesis: if you don't respond to whether or not you're not going to solve these problems -- whether or not you're not going to solve these problems -- you're not going to solve these problems.
2022-04-26 06:17:31 | INFO | fairseq.tasks.translation | example reference: when people don't take their pills, when people don't follow doctors' orders -- these are behavior problems.
2022-04-26 06:17:33 | INFO | fairseq.tasks.translation | example hypothesis: so if you think about it, it's almost as if the world is divided into almost any other region of the world, including the united states, east UNKNOWNTOKENINHYP, east UNKNOWNTOKENINHYP, east UNKNOWNTOKENINHYP.
2022-04-26 06:17:33 | INFO | fairseq.tasks.translation | example reference: so it's pretty sad to find that UNKNOWNTOKENINREF es, like so many other UNKNOWNTOKENINREF around the world, are losing their habitats.
2022-04-26 06:17:35 | INFO | fairseq.tasks.translation | example hypothesis: we've heard about this in the new UNKNOWNTOKENINHYP times, and this is just a few years ago, and this is just a few years ago, and this is just a few years ago, and this is just a few years ago.
2022-04-26 06:17:35 | INFO | fairseq.tasks.translation | example reference: we discovered bluegrass a few years ago, and we fell in love with it. we hope you guys will too.
2022-04-26 06:17:37 | INFO | fairseq.tasks.translation | example hypothesis: so what i'm going to do is i'm going to try to build a system based on the mechanical systems that we've developed to try to build a system based on the mechanical systems that we've developed.
2022-04-26 06:17:37 | INFO | fairseq.tasks.translation | example reference: so i was trying to, you know, take the engineer's version: can we build a mechanical system in inorganic materials that will do the same thing?
2022-04-26 06:17:39 | INFO | fairseq.tasks.translation | example hypothesis: we've talked a little bit about UNKNOWNTOKENINHYP, we've talked a little bit about UNKNOWNTOKENINHYP qaeda, we've talked a little bit about UNKNOWNTOKENINHYP qaeda, we've talked a little bit about UNKNOWNTOKENINHYP qaeda.
2022-04-26 06:17:39 | INFO | fairseq.tasks.translation | example reference: we consult to the media about canopy questions; we have a canopy newsletter; we have an email listserv.
2022-04-26 06:17:41 | INFO | fairseq.tasks.translation | example hypothesis: this is my talk today, and this is my talk today, and this is my talk today, and this is my talk today.
2022-04-26 06:17:41 | INFO | fairseq.tasks.translation | example reference: what my purpose of the talk today really is, is to sort of indelibly scar your minds with these charismatic and majestic UNKNOWNTOKENINREF.
2022-04-26 06:17:43 | INFO | fairseq.tasks.translation | example hypothesis: isn't it amazing if you're going to be surprised by this? it's not worth spreading. it's worth spreading.
2022-04-26 06:17:43 | INFO | fairseq.tasks.translation | example reference: now, it's no surprise that when you add consecutive fibonacci numbers, you get the next fibonacci number. right?
2022-04-26 06:17:45 | INFO | fairseq.tasks.translation | example hypothesis: but we're not going to wait until the next chapter, and we're not going to wait until the next chapter, and we're going to wait.
2022-04-26 06:17:45 | INFO | fairseq.tasks.translation | example reference: yet we dither, taking no action to deflect the UNKNOWNTOKENINREF id, even though the longer we wait, the more difficult and expensive it becomes. "
2022-04-26 06:17:47 | INFO | fairseq.tasks.translation | example hypothesis: he was one of my favorite writers, one of my favorite writers, one of my favorite writers, one of my favorite writers, one of my favorite writers, one of my favorite writers, one of my favorite writers.
2022-04-26 06:17:47 | INFO | fairseq.tasks.translation | example reference: he had this amazing series of hairs growing out of a mole on the left side of his face, which i'm told is very good luck.
2022-04-26 06:17:49 | INFO | fairseq.tasks.translation | example hypothesis: this is a first UNKNOWNTOKENINHYP e, and this is a first UNKNOWNTOKENINHYP e, and this is a first UNKNOWNTOKENINHYP e, and this is a first UNKNOWNTOKENINHYP e, and this is a first UNKNOWNTOKENINHYP e.
2022-04-26 06:17:49 | INFO | fairseq.tasks.translation | example reference: here's the first battery -- a stack of coins, zinc and silver, separated by cardboard soaked in brine.
2022-04-26 06:17:51 | INFO | fairseq.tasks.translation | example hypothesis: it was a group of people in the community who were thinking that the indus script was going to be the language of the indus script, because the indus script is the language of the indus script.
2022-04-26 06:17:51 | INFO | fairseq.tasks.translation | example reference: durkheim called this level the level of the sacred because he believed that the function of religion was to unite people into a group, into a moral community.
2022-04-26 06:17:54 | INFO | fairseq.tasks.translation | example hypothesis: but as a musician, i'm going to come up with an idea, and i'm going to come up with an idea, and i'm going to come up with an idea, and i'm going to come up with an idea.
2022-04-26 06:17:54 | INFO | fairseq.tasks.translation | example reference: but the UNKNOWNTOKENINREF match up if i rotate by a sixth of a turn around the point where all the trianUNKNOWNTOKENINREF meet.
2022-04-26 06:17:56 | INFO | fairseq.tasks.translation | example hypothesis: if there's anything you're going to do with it, please raise your hand, raise your hand, raise your hand, raise your hand, raise your hand, raise your hand.
2022-04-26 06:17:56 | INFO | fairseq.tasks.translation | example reference: there's little brochures all around outside, and if any of you have anything to do with children and care about their future, i beg that you pick up that brochure.
2022-04-26 06:17:58 | INFO | fairseq.tasks.translation | example hypothesis: and that's only about 10 percent of the speed of sound, and that's only about 10 percent of the speed of sound, that's only about 10 percent of the speed of sound.
2022-04-26 06:17:58 | INFO | fairseq.tasks.translation | example reference: and this is only done in four hours, 50 times faster than the current state of the art, at a cost that will be five to 500 times cheaper than the current options.
2022-04-26 06:18:00 | INFO | fairseq.tasks.translation | example hypothesis: so i can tell you about what i learned when i was a student at the university of UNKNOWNTOKENINHYP, and i can tell you about what i learned when i was a student at the university of UNKNOWNTOKENINHYP, and i can tell you about what i learned when i was a student at the university of UNKNOWNTOKENINHYP.
2022-04-26 06:18:00 | INFO | fairseq.tasks.translation | example reference: i'm fascinated with the idea of what happens when you merge UNKNOWNTOKENINREF with technology, and i remember reading about this idea of being able to reprogram UNKNOWNTOKENINREF, in the future, away from disease and aging.
2022-04-26 06:18:03 | INFO | fairseq.tasks.translation | example hypothesis: but the problem is that they're ignoring the political problem, and they're ignoring the political problem, and they're ignoring the political problem.
2022-04-26 06:18:03 | INFO | fairseq.tasks.translation | example reference: but the problem with relying on rules and inUNKNOWNTOKENINREF ves is that they demorUNKNOWNTOKENINREF professional activity, and they demorUNKNOWNTOKENINREF professional activity in two UNKNOWNTOKENINREF.
2022-04-26 06:18:05 | INFO | fairseq.tasks.translation | example hypothesis: i went to the national museum of natural history, and i went to the national museum of natural history, and i went to the national museum of natural history, and i went to the national museum of natural history, and i went to the national museum of natural history, and i went to the national museum of natural history.
2022-04-26 06:18:05 | INFO | fairseq.tasks.translation | example reference: i belong to an internet discussion forum, an UNKNOWNTOKENINREF internet discussion forum, and i asked them, i said, "since 1960, we've had exactly 204 UNKNOWNTOKENINREF heads of state, since 1960."
2022-04-26 06:18:08 | INFO | fairseq.tasks.translation | example hypothesis: and one of the things that really struck me immediately when i was thinking about this project is that there are a lot of people in this room that seem to have really strong opinion about this topic, and i'm really excited about it.
2022-04-26 06:18:08 | INFO | fairseq.tasks.translation | example reference: and as these dark clouds were circling me, and i was finding it really, really difficult to think of anything good, i said to myself that i really needed a way to focus on the positive somehow.
2022-04-26 06:18:10 | INFO | fairseq.tasks.translation | example hypothesis: think of it as being kind of like the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP of the UNKNOWNTOKENINHYP
2022-04-26 06:18:10 | INFO | fairseq.tasks.translation | example reference: for example, gUNKNOWNTOKENINREF age discharge, something you would think just simply goes away, but the laws regulating ship discharge of gUNKNOWNTOKENINREF age actually get weaker the further you are from shore.
2022-04-26 06:18:12 | INFO | fairseq.tasks.translation | example hypothesis: so he had to have a marketplace like this, and he had to have a marketplace like this, and he had to have a marketplace like this, and he had to have a marketplace like this, and he had to have a marketplace like this, and he had to have a marketplace like this.
2022-04-26 06:18:12 | INFO | fairseq.tasks.translation | example reference: see, he owned a UNKNOWNTOKENINREF mium plating company, and they had to move heavy steel parts between tanks of chemicals, and so he needed an industrial robot like this that could basically do the heavy lifting.
2022-04-26 06:18:15 | INFO | fairseq.tasks.translation | example hypothesis: and the women who are going to be threatened by sexual exploitation are going to be threatened by sexual exploitation.
2022-04-26 06:18:15 | INFO | fairseq.tasks.translation | example reference: and the religious police imposes the supposed UNKNOWNTOKENINREF ic way of life on every citizen, by force -- like women are forced to cover their heads -- wear the hijab, the UNKNOWNTOKENINREF ic head cover.
2022-04-26 06:18:17 | INFO | fairseq.tasks.translation | example hypothesis: if you go to the most vulnerable spot in the world, and you go to the most vulnerable spot in the world, and you go to the most vulnerable spot in the world, and you go to the most vulnerable spot in the world, and you go to the most vulnerable spot in the world, and you go to the most vulnerable spot in the world.
2022-04-26 06:18:17 | INFO | fairseq.tasks.translation | example reference: come with me to the bottom of the world, antUNKNOWNTOKENINREF tica, the highest, driest, windiest, and yes, coldest region on earth -- more arid than the UNKNOWNTOKENINREF a and, in parts, colder than UNKNOWNTOKENINREF.
2022-04-26 06:18:19 | INFO | fairseq.tasks.translation | example hypothesis: so here you can see, here you can see my father's hand clapping on the shoulders of his kneelyn dodson's shoulder clapping on the shoulders of his kneelyn dodson's kneelyn dodson's kneelyn dodson's kneelyn dodson's kneelyn dodson
2022-04-26 06:18:19 | INFO | fairseq.tasks.translation | example reference: that's kellar autumn, my former ph.d. student, professor now at lewis and clark, literally giving his firUNKNOWNTOKENINREF born child up for this test.
2022-04-26 06:18:22 | INFO | fairseq.tasks.translation | example hypothesis: it's one of the reasons that we believe that the only way to fight poverty is to embrace ethnic hatred and civil war and civil war and civil war and civil war and civil war and civil war and civil war.
2022-04-26 06:18:22 | INFO | fairseq.tasks.translation | example reference: however, while it's easier to think of us, the citizens, the police, the army, as the good guys, and them, the narcos, the carteles, as the bad guys, if you think about it, the latter are only providing a service to the former.
2022-04-26 06:18:25 | INFO | fairseq.tasks.translation | example hypothesis: and in that sense, i've come to realize that this is a kind of everyday life, a kind of romantic love, a kind of romantic love, a kind of romantic love, a kind of romantic love, a kind of romantic love.
2022-04-26 06:18:25 | INFO | fairseq.tasks.translation | example reference: and for the following 25 years, living in italy, living in UNKNOWNTOKENINREF, i doled out a piece of this romance to anybody who'd pay for it -- this sense, this aesthetic feeling, for the experience revolving around a designed object.
2022-04-26 06:18:27 | INFO | fairseq.tasks.translation | example hypothesis: because we have a problem in the UNKNOWNTOKENINHYP northwest of the UNKNOWNTOKENINHYP northwest of the UNKNOWNTOKENINHYP northwest of the UNKNOWNTOKENINHYP northwest of the UNKNOWNTOKENINHYP northwest of the UNKNOWNTOKENINHYP northwest of the UNKNOWNTOKENINHYP northwest of the UNKNOWNTOKENINHYP northwest of the UNKNOWNTOKENINHYP northwest of the UNKNOWNTOKENINHYP northwest of the UNKNOWNTOKENINHYP northwest of the UNKNOWNTOKENINHYP northwest of the UNKNOWNTOKENINHYP northwest.
2022-04-26 06:18:27 | INFO | fairseq.tasks.translation | example reference: because we've UNKNOWNTOKENINREF the problem in chubut province, which is like a state in argentina where punta tombo is -- so that's about 1,000 UNKNOWNTOKENINREF of coastline -- but we haven't UNKNOWNTOKENINREF the problem in northern argentina, uruguay and UNKNOWNTOKENINREF.
2022-04-26 06:18:30 | INFO | fairseq.tasks.translation | example hypothesis: one of the great things about this is that you're going to be able to pick up a knife and grab a knife and grab a knife and grab a knife and grab a knife and grab a knife and grab a knife and grab a knife and grab a knife and grab a knife and grab a knife and grab a knife and grab a kni
2022-04-26 06:18:30 | INFO | fairseq.tasks.translation | example reference: animal fan nellie mckay sings a sparkling UNKNOWNTOKENINREF te to her dear dog. she suggests we all do the same: "just go right to the pound / and find yourself a hound / and make that doggie proud / 'cause that's what it's all about."
2022-04-26 06:18:33 | INFO | fairseq.tasks.translation | example hypothesis: interestingly enough, the oil spills, the oil spills, the oil spills, the oil spills, the oil spills, the oil spills, the oil spills, the oil spills, the oil spills, the oil spills, the oil spills, the oil spills, the oil spills, the oil spills, the oil spills, the oil spills.
2022-04-26 06:18:33 | INFO | fairseq.tasks.translation | example reference: with streams and rivers drying up because of over-usage, rob harmon has UNKNOWNTOKENINREF mented an ingenious market mechanism to bring back the water. farmers and beer companies find their fates intertwined in the intriguing centurUNKNOWNTOKENINREF old tale of prickly pear creek. & lt; em & gt; & lt; / em & gt;
2022-04-26 06:18:36 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of people living in the UNKNOWNTOKENINHYP f of the UNKNOWNTOKENINHYP f of the UNKNOWNTOKENINHYP f of the UNKNOWNTOKENINHYP f of the UNKNOWNTOKENINHYP f of the UNKNOWNTOKENINHYP f of the UNKNOWNTOKENINHYP f of the UNKNOWNTOKENINHYP f of the UNKNOWNTOKENINHYP f of the UNKNOWNTOKENINHYP f of the UNKNOWNTOKENINHYP f of the UNKNOWNTOKENINHYP f of the UNKNOWNTOKENINHYP f of the UNKNOWNTOKENINHYP f of the UNKNOWNTOKENINHYP f of the UNKNOWNTOKENINHYP f of the UNKNOWNTOKENINHYP f of the UNKNOWNTOKENINHYP f of the UNKNOWNTOKENINHYP f of the UNKNOWNTOKENINHYP f of the UNKNOWNTOKENINHYP f of the UNKNOWNTOKENINHYP f of the UNKNOWNTOKENINHYP f of the UNKNOWNTOKENINHYP
2022-04-26 06:18:36 | INFO | fairseq.tasks.translation | example reference: and the reality of the society that we're in is there are thousands and thousands of people out there leading lives of quiet, screaming desperation, where they work long, hard hours at jobs they hate to enable them to buy things they don't need to impress people they don't like.
2022-04-26 06:18:39 | INFO | fairseq.tasks.translation | example hypothesis: and i'm going to tell you about one of my favorite UNKNOWNTOKENINHYP tions, which is, you know, there's a group of people in the muslim world who are trying to change the way we treat each other, and they're trying to change the way we treat each other, and they're trying to change the way we treat each other, and they're trying to change the way we treat each other.
2022-04-26 06:18:39 | INFO | fairseq.tasks.translation | example reference: and i organize it. and, well, it's also a bit different because an UNKNOWNTOKENINREF versus, let's say, a dance company finally is a negotiation between one's private world, one's UNKNOWNTOKENINREF tual world, the world of ideas, the world of aspirations, of UNKNOWNTOKENINREF tions, with the relationship of the exterior world and all the limitations, the naysayers.
2022-04-26 06:18:42 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, it's the basis of a whole bunch of different models that we're working on right now that we're working on right now that we're working on right now that we're going to be able to use this technology to create a completely new way to use technology for all of us to be able to use these new kinds of tools, and to be able to use these new kinds of tools, and to be able to use these new kinds of tools, and to be able to use these kinds of tools, and to be able to use these kinds of tools, and to be able
2022-04-26 06:18:42 | INFO | fairseq.tasks.translation | example reference: and i also hope that you share the idea that if engineers and UNKNOWNTOKENINREF can use all these different climatic parameters, it will be possible to create really good and comfortable outdoor conditions, to change our thermal perception that we feel comfortable in an outdoor environment, and we can do that with the best passive design, but also using the energy source of the site in qatar which is the sun.
2022-04-26 06:18:46 | INFO | fairseq.tasks.translation | example hypothesis: so i had a little bit of an anxious thought about this, and i said to myself, "you know, you know, i don't want to say anything about this particular problem that you've been suffering from, and i don't want to say anything about this particular problem that you've been suffering from, and i don't want to say anything about this particular problem that you've been suffering from for my own purposes, for my own purposes, for my own purposes, for my own purposes, for my own purposes, for my own purposes, for my own purposes, for my own purposes, for my own
2022-04-26 06:18:46 | INFO | fairseq.tasks.translation | example reference: i used to say that these people saved me, but what i now know is they did something even more important in that they empowered me to save myself, and crucially, they helped me to understand something which i'd always UNKNOWNTOKENINREF pected: that my voices were a meaningful response to traumatic life events, particularly childhood events, and as such were not my enemies but a source of insight into solvable emotional problems.
2022-04-26 06:18:49 | INFO | fairseq.tasks.translation | example hypothesis: for example, one of the things that happened to me at the end of the film is that when you go to a film festival and you say, "UNKNOWNTOKENINHYP, you know, here's the new UNKNOWNTOKENINHYP festival," you say, "UNKNOWNTOKENINHYP, here's the new UNKNOWNTOKENINHYP festival," and you say, "UNKNOWNTOKENINHYP, here's the new UNKNOWNTOKENINHYP festival," you say, "UNKNOWNTOKENINHYP, here's the new UNKNOWNTOKENINHYP festival," and you say, "UNKNOWNTOKENINHYP, here's the new UNKNOWNTOKENINHYP festival," and you say, "UNKNOWNTOKENINHYP, here's the new UNKNOWNTOKENINHYP festival," you say, "UNKNOWNTOKENINHYP, here's the new UNKNOWNTOKENINHYP festival," and you say, "UNKNOWNTOKENINHYP, here's the new UNKNOWNTOKENINHYP festival," and you say, "UNKNOWNTOKENINHYP, here's the new UNKNOWNTOKENINHYP festival, you know, here's the new UNKNOWNTOKENINHYP festival, you know,
2022-04-26 06:18:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at UNKNOWNTOKENINREF women is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-04-26 06:18:50 | INFO | fairseq.tasks.translation | example hypothesis: in fact, one of the things that we've been able to do today is to take this idea of the fact that we're going to be able to create a completely new kind of UNKNOWNTOKENINHYP tive technology, or a completely new kind of UNKNOWNTOKENINHYP tive technology, which is something that we've been able to do for the first time in human history, or a completely new kind of UNKNOWNTOKENINHYP tive technology, or a completely new kind of UNKNOWNTOKENINHYP tive technology, or a completely new kind of UNKNOWNTOKENINHYP tive technology, or a completely new kind of UNKNOWNTOKENINHYP tive technology, or a completely new kind of UNKNOWNTOKENINHYP tive technology.
2022-04-26 06:18:50 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of UNKNOWNTOKENINREF, and a lot of the design work that we're the most proud of with the aircraft came out of UNKNOWNTOKENINREF the unique problems of operating it on the ground -- everything from a continuouslUNKNOWNTOKENINREF variable transmission and liquiUNKNOWNTOKENINREF based cooling system that allows us to use an aircraft engine in stop-UNKNOWNTOKENINREF go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wUNKNOWNTOKENINREF folding mechanism that we'll see in a moment, to crash safety features.
2022-04-26 06:18:50 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 5.914 | nll_loss 4.42 | ppl 21.41 | bleu 4.58 | wps 1411.6 | wpb 2835.3 | bsz 115.6 | num_updates 5510
2022-04-26 06:18:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 5510 updates
2022-04-26 06:18:50 | INFO | fairseq.trainer | Saving checkpoint to /root/cs4650-final-project/checkpoints/checkpoint5.pt
2022-04-26 06:18:54 | INFO | fairseq.trainer | Finished saving checkpoint to /root/cs4650-final-project/checkpoints/checkpoint5.pt
2022-04-26 06:18:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint5.pt (epoch 5 @ 5510 updates, score 4.58) (writing took 5.958627400919795 seconds)
2022-04-26 06:18:56 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-04-26 06:18:56 | INFO | train | epoch 005 | loss 5.663 | nll_loss 4.161 | ppl 17.89 | wps 5425.1 | ups 1.51 | wpb 3583.6 | bsz 145.4 | num_updates 5510 | lr 0.000426014 | gnorm 4.217 | train_wall 587 | gb_free 7.2 | wall 3503
2022-04-26 06:18:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2022-04-26 06:18:56 | INFO | fairseq.trainer | begin training epoch 6
2022-04-26 06:18:56 | INFO | fairseq_cli.train | Start iterating over samples
Traceback (most recent call last):
  File "train.py", line 595, in <module>
    if __name__ == "__main__":
  File "train.py", line 588, in cli_main
    else:
  File "/root/cs4650-final-project/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "train.py", line 220, in main
    # train for one epoch
  File "/opt/conda/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "train.py", line 346, in train
    ):
  File "/opt/conda/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/root/cs4650-final-project/fairseq/fairseq/trainer.py", line 823, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/root/cs4650-final-project/fairseq/fairseq/tasks/fairseq_task.py", line 516, in train_step
    optimizer.backward(loss)
  File "/root/cs4650-final-project/fairseq/fairseq/optim/fairseq_optimizer.py", line 95, in backward
    loss.backward()
  File "/opt/conda/lib/python3.8/site-packages/torch/_tensor.py", line 363, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
